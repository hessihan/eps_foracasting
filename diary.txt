テーマ「企業収益の予測」
懸賞論文でGDPナウキャスト。そのノリでミクロデータ扱っていきたい --> 企業収益？
* 株価でもいいが、、、株価はむずそう。(ボラ？)
* 企業収益予測ができる --> 企業のバリュエーションにつながる。正しい企業収益予測に価値あり。
* 「ナウ」要素はどうするか？未定。
って感じで考えてる。
手法にNNとか、評価指標にMAPEとか加えればいくらでも懸賞論文から拡張できる。

2020/02/16
Jeffery et al. (1996)
従来の企業収益予測モデルのパフォーマンスとと、ANNを用いたパフォーマンスに大差ない。(なんなら従来のほうがいい)。
そもそもANNがどうなってるかわからん。

やるべきこと:
* 企業収益を予測することの意義(場合によってはテーマを変える。)
* 企業収益の構造。企業収益そのものについての勉強(Finance, Accountingsの知識)
* Time Series Forcasting について。(収益予測でいろいろ引用されてるし重要)
* 企業収益 Forecasting について。(二個目と同じようなニュアンスで。)
* ANNの勉強(なるはやで。大変そうだけど、自分で使えるくらいには。)
* 論文の構成。(戦略を考える。論文の意義。結果がどっちに転がってもいいように。)
* 「ナウ」要素をどうするか。このままだとただのForecasting。別にいいけど。

まずは論文のメッセージからかな。GDPのときも、「現状を早く正確に-->政策」って感じだったし、そういうのを考える。
次にTime Series Forecasting について体系的に把握。GDPの時は先生から教わったり、自分たちオリジナルが多かったけど、みんながどんな感じでやってるかをアカデミックに知っておこう。
上の二つをうまく組み合わせて、論文のコアを作る。あとそこにテクニカルな機械要素いれればおけ。今回はDeepもやるとかっこいい。

02/17

いくつか論文印刷。
Zhang et al. (2004):
NNを使ったEPSのForecasting。Nowではないけど、これがテンプレか？。まずこれを読もう。
Carabias (2018):
LSEの先生。企業単位のEarningsをナウキャスティングする大切さ、というかEarningsの構造を理論から攻めてる印象。後で読もう。
Ahmed et al. (2010)
Econometric Reviewsだし有名じゃね？知らんけど。そもそものMLでのTS Forecastingについて考える。いいこと書いてそう。後で。
ちょっと見たけど、かなり実践的で、実際にコード書くときとか、分析時に役立ちそう。

*GDPとデザインを対応させよう
テーマ:マクロ予測(GDP) --> ミクロ予測(EPS)
意義: 早い政策 --> 投資家、マネージャーにとって、、、
データの構造: リバイズ時系列 --> 企業ごとにちがう時系列(panel?)
テクニック: 機械学習的手法 --> 機械学習的手法(+NN)
研究内比較: 機械学習手法間の比較 --> 機械学習手法間の比較、従来のモデル(Brown Rozeff)との比較
バトル: JCER --> ???
結構似せていく感じ。

EPS予測においていろんな手法使ってる論文少なそう。
かつ「ナウ」要素入れたら,,,
--> ここら辺がオリジナリティ?

Zhang et al. (2004):
EPSの予測は、投資家のポートフォリオマネジメントと、企業の資源配分に役立つ。
linear vs. non-linear, univariate vs. multivariate
EPS予測は、linear(time series ARIMA)が多数派。
	quaterly EPSはfinancial time series --> non-linearである。(Abarbanell and Bushee, 1997)
EPS予測の研究の多くはunivariate
	"fundamental accounting variables"(accounts receivables, inventory, capital expenditures) --> いろんな変数使うべき(Abarbanell and Bushee, 1997)
ビジネスコンテクストでのEPS予測において、NNは不適切だといわれてきた。(Callen et al., 1996 など)
この論文では、fundamental accounting variablesを説明変数としてmultivariate な NN を使う --> outperform ARIMA!

Carabias (2018):
まだしっかり読んでないけど、earnings のナウキャストをマクロ予測の結果を説明変数として使ってる感じ。GDPナウキャストとつなげる超大作の予感!?

02/19

Carabias (2018):
マクロ経済ダイナミックファクターが、企業四半期収益の説明をしている。
multivariateではaccuracyをあまり注目してない。regって有意-->俺のモデルは大事な情報持ってるねって感じ。
ダイナミックファクターモデルでナウキャストしてるのは、GDPとかではなく、ファクター？
そしたら、機械学習で企業四半期収益をなうキャストする場合、
* マクロ変数 -ナウキャスト-> ファクターのナウキャスト値? -ナウキャスト-> 収益のナウキャスト値
をするのか？一回ファクターをなうキャストする意味は?
* マクロ変数 -ナウキャスト->  収益のナウキャスト値
でいいのでは？
ちなみにこの論文、CAR使って、ファクターが株式市場も説明する的なこともしてて盛沢山

次に読む -->
Abarbanell and Bushee (1997): fundamental accounting variables
Dhar and Chou (2001): nonlinear Predicting Earnings Surprises and Returns

03/11
CSC321 lec04
Multiple classification
soft-argmaxをベクトルでWで微分してみたい。
回帰中級と対応させてみたい。logistic regression
用語の対応スライド作成してみたい。
tut2のinput space, weight space constraints がよくわからん。
すべての次元において制限内に収まってるようなweightの組み合わせがfeasible?
softmaxのプロットをしてみたい(2次元?)

0403
今日から毎日修士論文3h時間計画	
まずはデータを集めないと何も始まらない。
y, X。ついでに何でこのXなのかも説明就くように。

0420
計画書作成

～～～
②修士論文計画書の提出

　【提出締切】5月9日（土）17時

　【提出先　】11号館3階商学研究科事務所

　【提出方法】計画書フォーマットを商研HPよりダウンロードのうえ提出。

　　※主査1名・副査2名の署名捺印が必要です。

　　　学内教員の署名捺印を期日までに得ることが難しい場合は、署名捺印がない

　　　状態での提出を受け付けます。その場合はメール（gsc-ac@list.waseda.jp）

　　　にMSワードファイルを添付のうえ、期日までにご提出ください。

　　　副査を学外教員に依頼するする場合は、商研事務所宛てに期日に余裕をもって

　　　ご相談ください。

　　※ご参考：計画書フォーマット

　　　　https://www.waseda.jp/fcom/gsc/assets/uploads/2015/01/MA_thesis_plan.doc

 

■修士論文のスケジュールについて（予定、変更可能性あり）

　　仮指導期間            ：4月20日（月）～5月9日（土）

　　計画書提出            ：5月9日（土）まで

　　副査指導期間        ：11月16日（月）～20日（金）

　　論文提出日　　　 ：2021年1月7日（木）

　　口述試験日程　     ：2021年1月26日（火）・27日（水）

～～～
以上、よろしくお願いいたします。

イントロのイメージで。

FLOW
* EPSの予測は大事。
* 企業内での財務分析(ファンダメンタルズ分析)<日本論文引用>や
  外部の投資家の投資判断指標<日本論文引用>・M&Aの株式交換比率の算定<日本論文引用>に用いられる。
* EPSは四半期会計期間で集計され、発表にラグがある。たとえば～
* だから大事
* 従来のEPS予測モデルは統計モデル(線形時系列モデル i.e. ARIMA)が使われる<できれば日本論文そもそも予測してない説>。
* 従来のEPS予測モデルはunivariate<できれば日本論文そもそも予測してない説>
* 最近の論文の指摘、EPS含めた金融時系列データは非線形である<Callen et. al. (1996)>
* 最近の論文の指摘、EPSを説明する説明変数はある。より予測の精度を上げる可能性<Abarbanell and Bushee (1997)>
* NNを用いて上記の指摘を反映し、実際に米国のデータでやってる研究がある。<Zhang et. al. (2004)>
* Ridgeを用いて、オープンなデータ株価のみで米国EPS予測<Kamp et.al. (2014)>
* 一方、日本ではそもそもEPS、企業収益予測に関する文献は少ない("売上予測"ではないよね？)株価予測ならあるけど。
* 日本の機械学習を用いた企業収益予測の論文の例も少ない<鷲尾 et. al. (2007)> 
* <-- 鷲尾のあら捜しして、この論文の価値を上げる。
* 本稿は東京証券取引所に上場している企業のEPSを機械学習的手法を用いて予測する。

* 予測の手法はNN(MLP)をメインにやってみる<Ahmed et. al. 2010>
* Zhang et. al. (2004)は単純な3 layer, logistic funcなので、もっとかっこいいやつ(LSTM, RNNなど)を使う。(理由も添えて)

* 予測後、vs 統計モデル
* 予測後、vs アナリスト(IBES?)
* 予測後、コンビネーション
* 予測後、外部の投資家の観点から、earnign surpriseを見てみる。<-- 味付けポイント

まずはZhang et. al. (2004)を真似して、univariate (Xはラグ1~4)のNNをやってみる。

0424
なぜEPSなのか、企業収益の指標はほかにもある。(ROA, ROEとか)
EPSの意味(規模に左右されない)などをしっかりまとめておく必要がある。EPSを予測する意味。

0503
LSTMは使うべし
どっかでかっこいいvisualizationしたい
https://medium.com/asap-report/visualizing-lstm-networks-part-i-f1d3fa6aace7

0714
久しぶりに論文そのものに取り組む
授業のレポートの内容が被るため、ついでに手法の部分の書きをやっとく。
referenceリスト(.docx)の作成

1007
今日からさすがに毎日やらないとやばい
reading
https://www.google.com/search?q=EPS+forecasting+deep+learning&oq=EPS+forecasting+deep+learning&aqs=chrome..69i57.13883j0j1&sourceid=chrome&ie=UTF-8

https://www.saa.or.jp/journal/prize/pdf/1996itou.pdf
https://www.jstage.jst.go.jp/article/jbef/3/0/3_0_246/_pdf/-char/ja

### データを集めるうえで決めるべきこと
*予測対象企業は?(上場?日経平均?金融機関除く?)
*yの形式は?(EPS?予想EPS?earning surprise?)

1012
データを集めた。(2000~現在までの日経225のEPSと会計データ)
予想データがまだよくわからん。
とりあえずデータセット作るか。

1013
日経225にしても、 採用企業は推移する。
https://ja.wikipedia.org/wiki/%E6%97%A5%E7%B5%8C%E5%B9%B3%E5%9D%87%E6%A0%AA%E4%BE%A1
他の文献ではどうチョイスしてる？

基本は
- 上場企業
- 3月決算企業
- 一般事業者 (金融業:銀行,証券,保険を除く)

だからかなり多い

使ってるデータベースは

-
-
-

1202
データコンペ終わって再開。
データづくり最優先

そもそもyを何とするか、、、
EPSでもいいけど、他の研究では

* 売上高 (収益・利益ではない?業績ではある?)
* 売上総利益
* 営業利益
* 経常利益
* 税引前当期純利益
* 当期純利益

など、PLに載ってる利益を予測してるケースが多そう?
上から不確実性が少なく予測しやすい?
https://m-repo.lib.meiji.ac.jp/dspace/bitstream/10291/607/1/keieironshu_46_1_3.pdf
https://qiita.com/teatime77/items/e480ae958bf81750753b

###########################################################
ってかこの人最強、パクらせてもらおう
https://qiita.com/teatime77
(アナリスト、経営者比較と、予測のアプリで差別化)
###########################################################

でもめんどそうだし、5年しかないからやめとこう、アプリの時に検討。

いや、やっぱりEDINETにするか、5年が短いかどうかはまたあとで考えよう。

データゲット、xarrayでも作るか

12/04
森(1998)はデータが超すくない、セッティングはわかりやすい(時点とか、データソースとか)
-->データ多めでやってるフューチャーリサーチもなさそう。

https://qiita.com/teatime77/items/e480ae958bf81750753b
teatime77の予測のセッティングはクロスセクション?各社のtrainingdata 1つしかない!?
散布図プロットはわかりやすい、過大・過小予測をパッと見れる。
これを、各企業別(teatime77は1時点の全企業、クロスセクション)に見れるといいかもね。

ギモン点
* クロスセクションによるモデル推定をしてるのなら、モデルは1企業の時間の特徴ではなく、
   Y: 利益、X: 会計データの横の関係(企業たくさん)を捉えてる?
* 粗利益とか利率の計算をそれぞれ出してるけど、NNはあらゆる線形関係を捉えるからわざわざX増やす意味ないんじゃね?

12/08
時系列を追うのは大変だし、時間が変われば無理げー(構造変化はでかい)
そこで、クロスセクション予測をする(現状のEDINETとかの公開データベースは期間5年だけ、企業数は個人もあるけど3603)
クロスセクション収益予測の文献 Hou et al. (2012)は比較対象

xr.DataArrayを作成
dims、coordsはめちゃめちゃ迷う、次元増やすとdataが複雑になるし、元データ2次元DataFrameからの変換がだるい。
--> 2次元numpyから多次元numpy変換ツールでも作るか(カラム指定して変換、メインはnp.reshapeだろうけど)

12/09
キーが非常に大事、
キーの組み合わせはすべてuniqueである
--> Multiindexに重複がない (balancedである必要はない)
--> 多次元配列に変換 (balancedにするために足りないindexのデータにNaNを敷き詰める)
NaNが大量のデータになるのは当たり前。

FQが学外でも使えるようになった(期間限定2月まで)

FQから、時系列の長いデータをとりあえずとってきて、論文用に確保する?
パッケージ用にEDINETは使えるようにしとく。

明日当たりに今考えてることをまとめておこう。

1211
まだまとめてないです
とりあえずマスターデータ ds_ins.pkl完成
元のcsvデータ30Mに対し、4G、ちょっとでかすぎか(nan大量)
使う当期だけ抽出するか

2021/01/08
データはやっぱりCSVがいいよね、パネルにしますか、、、、4GのほとんどがNaNだし意味ない。使うときに使う量だけxarrayにすべき。(なんだったらいらない)
とりあえず、ARと簡単なRNNをtest.ipynbで予測してみる。(時系列、1社。cross sectionは後で。)
データはFQから、一企業とってくる。FINHISA(1997 1期~)らしいので、これに合わせるか。
自動運転をうまく使う。
累計でやるべきか、三ヶ月でやるべきか、、、実際の企業の決算は累計でやることが多い模様。
データをいつからにするべきか、企業をいくつ使うべきか。TOYOTAは2002年度から四半期報告してるけど、全ての企業がやってるわけじゃないし、中間にするか?

2021/02/20
太朗と話した。
* P/Lである収益はB/Sより予測しづらそう。
* 会計基準はIFRSでいいけど、基準変更に注意。変更ダミー変数とか必要かも。
* 本当に当たる収益予測なら、 + or - 予測でもすごい価値がある。バイナリ予測も試そう。

まずはPytorchを使えるようになる。
そのためには、行列を回せるようにする。Vector Jacobian Productを習得。

あと、ゆくゆくは"Pytorch + ROCm + AMD Radeon Vega"をしてみたい。(GPU回せるとかっこいいじゃん)

2021/02/27
3layers FFNNを作ってみた neural_network.py
hidden layer unit の数をどうしたらいいかわからない。
適当に10 (さすがにサンプルサイズよりもでかくしたらまずそう?)
input --> Linear1 --> Sigmoid --> Linear2

SGD, iteration 20000, learning rate 1e-6
結果、lossは減らしてるけど、変な感じに(yの平均値がずっと続く感じ) ヘタクソ

試しに色々やってみる

0.hidden layer unit の数を変えてみる
unit数多いほう(100とか)がlossの減るスピードは若干早くなる
でも予測値は平均値がずっと続く感じのまま上下してるだけ、ヘタクソ loss 16484.91015625

1. Linear1 --> Sigmoid 消す (hidden layer なし)
つまりAR(4)と一緒?、すごくうまく当ててる、AR強い (iteration意味なし) loss 5226.3388671875

2. Linear1 消す
最初と似たようにずっと平均まわり、ヘタクソ

3. Sigmoid 消す
つまりFully connected Linear を無意味に2回繰り返すだけ。1. の結果と同じ。

考えられること:
* hidden layer が足りてない? --> 2 hidden layer にしてみる
* Sigmoidが悪さしてる? --> non-linearityの再現にはnon-linear activation不可欠だけど、ReLUにしてみる?
* そもそも Univariate Time Series は NN にとって無理げー --> 諦めて LSTMにワンチャンかける?

2021/03/01
hidden二層にしてもヘタクソなまま。
Univariateだと、そもそも予測できるだけの情報がない?
train-test-splitして、testの予測精度だけ見るならARより平均値の方がいいかも?

num_iteration 200000にしても、lossは減るけどヘタクソ (前半が完全一致) step 199999: loss 6371.216796875

lrを大きくしても結果変わる
パラメータ更新アルゴリズム変えても結果変わる
Adam, lr大き目(=1e-3, 1e-4とか)にするとすごく結果がいい(overfitting かもだけど)
Adam lr=1e-2, num_iteration=20000 --> step 19999: loss 1892.8258056640625

hidden unit 100にしたらすごいことになった!!!

Adam lr=1e-2, num_iteration=20000, hidden_unit=100 --> step 19999: loss 384.6512451171875
まあこれはどう見ても過学習。ちゃんとvalidationで決める必要あり?このあたりのマナーも調べないと。

ニューラルネットはハイパーパラメータがめちゃくちゃ大事かもしれない。

次やること
* ARIMAをmoving windowにする(window: 30 period?)
* train-test-splitして、train MSE, test MSE それぞれ出して over fitting かどうかを判別
* LSTMの実装
* さっさと 会計変数 Xを導入。

検討項目
* データをnormalizeとかする? (data preprocessing)
* 選ばれし6会計変数だけでなく、変数選択前提でめちゃくちゃたくさんX持ってきてLASSOとかで選ぶ?
* パラメータ更新アルゴリズムはどれがいい? Adam, RMSProp, Adagrad, SGD ...
* lr はどうしたらいい? 10^-6 ~ 1 の間が一般的らしい。基本は最適化方法はなくtry and error, lr は最も重要なhyper param
* https://machinelearningmastery.com/learning-rate-for-deep-learning-neural-networks/
* DL のハイパーパラメータ(learning rate, hidden unit, iteration ...)の決め方のマナー。

2021/03/04
git, githubまわりの勉強
githubに新しいdirectoryを作成

2021/03/10

    # y, x (lag 1 y) 
    # !!!!!! lag 4 for quarterly ? or statsmodel have done well in sm.tsa.SARIMAX?
    y = ts["１株当たり利益［３ヵ月］"].drop(0, axis=0)
    y = y.reset_index(drop=True)
    x = ts["１株当たり利益［３ヵ月］"].shift(1).drop(0, axis=0)
    x = x.reset_index(drop=True)
    
このコードは不要かも、statsmodel が勝手にラグとってくれてるはず(order入れてる時点でそりゃそうだろう)

    y = ts["１株当たり利益［３ヵ月］"]
    
でよし。

SARIMAのRolling window, expanding windowを追加 (Zhang et al (2004) は Rolling)
forecast accuracy モジュール追加

先行研究のMAE, MAPE, MSEと比較
自分の値が、特にMAEやMSEが桁外れにおおきい、正規化してないから?
MAPEは単位関係ないから比較可能だと思うけどそれでも倍以上違う、トヨタが外れているだけ?

from Callen et al (1996)

"
Mean absolute percentage error (MAPE),
mean absolute deviation (MAD), and mean
square deviation (MSD) metrics are computed
for each firm. 
The reported MAPE and MSD metrics are
normalized by the forecast. We also computed
these metrics normalized by actuals and obtained
similar results.
For the MAPE and MSD metrics, filters were
used to eliminate outliers whenever [;,[ was less
than the filter values (F). The filters took on the
values $0.025, $0.05, $0.075, and $0.10. For the
MSD metric, these filters exclude from 127 (F =
$0.025) to 650 (F = $0.100) cases out of a total of
14 504 (= 296 x 49) earnings forecasts for each
model (i.e. from 0.9% to 4.5%).
"

正規化してるっぽい。、あとはずれ値はフィルターしてる。

モデル間の複数企業の予測の精度を比較する場合はどうしたらいいの?
各企業の精度指標を計算 --> そのあとは?指標の平均? Diebold-Mariano test とかはどうすればいい?

ちなみに、今in-sampleのフィットの具合は見てないけど、見た方がいいかな?(over-fittingしてるかわかりそう)

expanding より rolling の方がパフォーマンスよさそう。

2021/03/11
windowなしのFFNNの精度をSARIMAと比較。
FFNNの予測はAdam法にランダム性がある限り毎回の精度もランダムでばらつきはあるけど、1,2位くらい(SARIMA-BRと接戦) --> 予測値の分散? (Variance of Prediction)
ここでアナリスト予測と経営者予測のデータとも比較したい。

トヨタについてだけど、
日経新聞社予測はどうやら半期予測っぽい、どうやって比較しようか?
経営者予測にいたっては、半期どころか年に一度の累計しか出していない。四半期予測の項目は実績値になっている。

2021/03/12
ベイズの話
1.モデリング かんたん
尤度P(D|H)とパラメータの事前確率P(H)(自分のbelief、わかんなきゃ適当に平均０の超幅広い一様分布、つまり何もわからない状態)掛けたやつ(分母はよくわからんやつP(D))がある難しい分布に従うパラメータの事後確率P(H|D)(データが条件)、求めたいもの。先のbeliefからデータが与えられたことで分布が修正される。
2. 推定
P(H|D)の難しい分布の平均や分散はわからない、でもその分布から乱数を発生させることはできる。だから乱数発生させて分布の特徴をみる。
ベイズの分布の平均出すと、だいたい最尤推定量と一致する（事前分布に強いbeliefをかけるとかけ離れることはある。）それでも使い分けるのは、推定するモデルの複雑さによる。簡単なのは普通に推定、係数がサンプル(金融なら企業ごととか。マーケットベータ\beta_iとか?)に違うような複雑なモデルはベイズの方が早いことがある（複雑すぎるとそもそも普通の推定できない）。でもまあ結果は基本一緒。

論文の話
SARIMAに勝った負けたで終わるのは避けるべき。
なにか味付けが必要（大量にX入れてlasso変数選択とか）
6つの会計変数でもやる、Lassoで選ばれたのが会計変数と一致してもしなくても価値がある
50ピリオドは悪くない。
でも複数企業でやるべき、各社に対して予測値系列とMAPEが出せる。MAPEの全社平均を各手法間で値の単純比較（複数主体の時系列予測値の違いの検定は今の所なさそう?少なくとも片山先生は知らない。こういうときこそエコノメトリシャン、既存の検定dm testとかを見て、複数主体でも通じるような手法を考え、シミュレーションで良さそうなテストができたらパッケージにしてリリースする流れ。）
経営者予測は年間、一社だとtest4年で少ないけど複数社で一気に比べるのもありかな。
とりあえず次X入れる

2021/03/15
次やること、
* y(他の利益)とXのクリーニング --> data_preprocessing.py をもとに dataset.py をデータ作成ファイルとし、dataset class をモジュールmod_dataset.pyとして作成。
* X 入れる --> main.py
* NN の moving window (window の module分離化をし、各手法に対応できるようにする) --> module_window.py の作成
* NN の Hyper parameter tuning 

2021/03/25
予測の時、モデルの話だけじゃなくて、yの発生するプロセスもしっかり論じることが大切。EPSがどうやって算出されるかを今一度しっかり調べておくこと。
[累計]だけだと虫食いがあったりするから結局[3ヶ月]も参照して穴埋めする必要あり。
悲報: [累計]と[3ヶ月]では値が違うやつがある説(販管費)

2021/03/30
* Creating dashboard interface using Python Dash.

2021/03/31
太朗との話し
* 教科書から勉強。利益は当期の払った分どれだけ稼いだかの"概念"
* 収益予測はなぜ大事? --> 株価の理論値算定に使う(割引現在価値の分子)
* 実務、M&Aの買収価格の算定

2021/04/08
De-trending, de-seasonizing, standardizing will make better predictions.
https://m.youtube.com/watch?v=svNwWSgz2NM&feature=youtu.be
どうやってoriginal valueに戻す?

2021/04/13
累計値の欠損は、3ヶ月で埋めて、累計から四半期に変換。
累計から四半期変換したデータと3ヶ月データで違うところもあるが(理由不明)、3ヶ月データは欠損が多いため、
3ヶ月で欠損処理した累計から四半期変換したデータを用いる。
一応データクリーニングは完了
資本的支出はinterpolateで埋めちゃったけど、cumulativeかseasonalityがあるに違いない。(BSだから資産、cumulativeではないはず?)
stationalize, normalize(scaling)はまだ。資本的支出はdeseasonalizeしてからinterpolateするべき?

Question: 欠損値処理はstationalize, normalizeしてからか、stationalize, normalizeは欠損値処理してからじゃないとうまくできないのか?

次回はとりあえずstationalize, normalizeせずレベルのままモデルにX入れてみる。

2021/0414
前回2007年からだったけど、今回は2002年からのデータ。72 periodになってる。
univariateを推定しなおし、BR >> MLP, G >> F, RW の結果に。(MLPはwindowなし。)

	random walk	SARIMA: BR	SARIMA: G	SARIMA: F	MLP
MAE	87.295625	66.077148	74.753328	88.923733	75.874780
MAPE	1.207818	0.689469	1.218414	1.300829	0.749869
MSE	12151.358681	7104.267580	11791.377932	14700.944361	8567.061686
RMSE	110.233201	84.286817	108.588111	121.247451	92.558423
RMSPE	3.113151	1.466094	3.329172	3.343005	1.575647

NNの結果はランダムなので、seedで固定。

時系列モデルの多変量版
SARIMAX(逆の因果無し) or VAR(y, xお互いに関係)?
vector autoregressionの方がよさそう?

どちらにしろ、今の状態だとwindowがSARIMAに固定してあるから、他のモデル(SARIMAX, VAR, MLP, LSTM)に応用が利かない。

次回
* モデルをインプットとするようなwindow()関数を作る。
* X を入れた予測
* NN の window

2021/04/17
https://drivendata.github.io/cookiecutter-data-science/#requirements
リポジトリの構造、デザインをわかりやすく改良。
