% https://home.hirosaki-u.ac.jp/masumi/100/
\documentclass[a4paper, 12pt]{jsarticle}
% \documentclass[a4paper]{jsarticle}
\usepackage{bm}
\usepackage[dvipdfmx]{graphicx}
\usepackage{ascmac}
\usepackage{amsmath}
% bibtex ハーバードスタイル
% https://www.imperial.ac.uk/media/imperial-college/administration-and-support-services/library/public/LaTeX-example-Harvard-apr-2019.pdf
\usepackage{natbib}
% argmin定義
\DeclareMathOperator*{\argmin}{arg\,min}
% ハイパーリンク
\usepackage[dvipdfmx]{hyperref}
\usepackage{pxjahyper}
\usepackage{booktabs}
% 表を横に
\usepackage{lscape}
% 表の脚注
% https://qiita.com/kumamupooh/items/38795811fc6b934a950d
\usepackage{threeparttable}
% 表のセル内改行
% \usepackage{tabularx}
% \usepackage{array}
% \newcolumntype{C}[1]{>{\centering\arraybackslash}p{#1}}
% 番号付き箇条書き
\usepackage{enumerate}

\hypersetup{
setpagesize=false,
 bookmarksnumbered=true,%
 bookmarksopen=true,%
 colorlinks=true,%
 linkcolor=black,
 citecolor=black,
}

\title{機械学習アルゴリズムによる\\
  日本企業の四半期利益予測}
\author{早稲田大学大学院商学研究科 商学専攻\\
  35201064　王思涵}
\date{2020年月日}

\begin{document}
\maketitle
\tableofcontents

\part{はじめに}

1株当たり利益（Earnings Per Share: EPS）は株式1つ当たりに対する企業の当期純利益を表した指標である. EPSは企業の当期純利益を発行株式数で割ることで求められており, 規模に依存しない企業の収益性を示す. 企業外部のステークホルダーである投資家は, 企業の将来のEPSの予測をもとに, 収益性の高いポートフォリオを構築したり, 将来の株価収益率を算出して投資判断を行う. また, 企業内部の経営者は将来のEPSの予測を用いて, 営業予算の作成や設備投資の判断などの重要な意思決定を行う. したがって, EPSを正しく予測することは企業内外の幅広いステークホルダーにとって重要である. 

企業の将来利益の予測は, 人的な予測と, 統計的・機械的な予測の2つに大別できる\citep{sakurai1990}. 人的な予測の代表として, アナリスト予測がある. アナリスト予測とは, 株式市場分析の専門家である証券アナリストが公表する利益予測である. 他方, 統計的・機械的な予測とは, 過去の実績データをもとに何らかの時系列モデルを用いて将来の利益を予測することである. モデルに基づく予測は, 予測値を導出するまでの過程を全て機械化できるため, 人的な予測に比べてコストが低いという特徴を有している\citep{sakurai1990}. 

統計的・機械的な予測に関する研究で用いられているモデルは, 1)「単変量」か「多変量」か, 2)「線形」か「非線形」か, の2つの観点で分類できる\citep{zhang2004neural}. 従来の, モデルに基づくEPS予測の研究の多くは, 自己回帰和分移動平均(AutoRegressive Integrated Moving Average: ARIMA)モデル\citep*{box2015time}などの単変量で線形な統計的時系列モデルを用いている(e.g., 英語のもっと古い論文). 一方, 近年の研究では, 「ファンダメンタル会計変数」を用いた多変量モデルによるEPS予測の研究が増えている. ファンダメンタル会計変数とは, 売掛金, 棚卸資産, 資本的支出といったいくつかの会計変数のことであり, これらの変数には将来のEPSを予測する情報があるとされている\citep{lev1993fundamental, abarbanell1997fundamental}. また, 四半期EPSデータには非線形性があるとされており\citep*{hopwood1986univariate}, これを考慮するために, 予測モデルに非線形性を反映させている研究も盛んである. 中でも従来の統計的時系列モデルに代替されるモデルとして, 機械学習アルゴリズムが注目されている. 機械学習アルゴリズムは, 統計的時系列モデルに比べて, 高次元データの処理に長けたモデルや非線形性を捉えられるモデルが豊富にある\citep*{cao2020fundamental}. そのため機械学習アルゴリズムを用いることで, 多変量なファンダメンタル会計変数から予測情報を抽出し企業利益の非線形を捉え, 高い精度のEPS予測が得られると考えられる. 

機械学習アルゴリズムによる企業のEPS予測の研究の前例として, \cite{zhang2004neural}はアメリカのニューヨーク証券取引所の上場企業, \cite*{cao2009forecasting} は中国の上海証券取引所と深セン証券取引所の上場企業, \cite{etemadi2015earnings}はイランのテヘラン証券取引所の上場企業を対象に, 機械学習アルゴリズムの1つであるNNモデルによる四半期EPSの予測を行っている. また, \cite*{cao2020fundamental}はアメリカの上場企業を対象に, いくつかの代表的な機械学習アルゴリズムを用いた年次EPS予測を行っている. いずれの研究においても機械学習アルゴリズムが精度の高い予測をもたらす結果となっている. 

このように近年, 統計的・機械的な手法によるEPS予測の研究分野では, 機械学習アルゴリズムを用いて, モデルに多変量と非線形な特性を反映させることで予測の精度が向上することが様々な国のサンプルで確認されている. しかし, \cite{ota2006}によると人的な予測と従来の時系列モデル予測の精度比較研究については, 明確な結論が出ていないにも拘らず, モデルによる予測よりも人的な予測の方が適切であると暗黙裡に見なされており, 時系列モデルによる予測の研究は, 現在では衰退しているとされている. 現に日本における統計的・機械的なEPS予測の研究は限定的で, 従来の線形時系列モデルの適用に留まっており, 高い予測精度が期待される機械学習アルゴリズムによる日本企業データを用いたEPS予測の研究は, 筆者の知る限り存在しない. また, 日本ではモデルによる利益予測が衰退したあとの2008年度に四半期報告制度ができているため, 四半期データを用いたEPS予測の研究もない. 

そこで本稿は, 日本企業データにおいて, 代替的な時系列予測モデルである機械学習アルゴリズムが統計的・機械的な手法によるEPS予測の精度を向上させるのか, 人的な予測よりも高い精度の予測をもたらすのかを検証する. 具体的には東京証券取引所一部上場企業を対象に機械学習アルゴリズムによる四半期EPS予測を行い, 得られた予測値を用いて従来の線形時系列モデルによる予測やアナリストによる予測と精度比較をする. 追加的な検証として, 機械学習アルゴリズムによる予測値と各手法による予測値それぞれに基づいた株価予想利益率からロング・ショートポートフォリオを構築し, それを日本の証券市場に適用させて, 機械学習アルゴリズムによる予測と各手法による予測の投資指標としての有用性を考察する. 

% さらに, 機械学習アルゴリズムによる予測と各手法による予測の組み合わせ予測\citep*{bates1969combination}を求めて, 機械学習アルゴリズムによる予測に他の予測手法の精度を向上させる情報を含んでいるかどうかを調べる. 

% 本稿の構成は以下のとおりである。第2章では、、、

\part{過去の研究}

これまで多くの企業利益予測の研究で、統計的・機械的な予測手法間の精度比較、統計的・機械的な予測手法と人的な予測手法の精度比較、人的な予測手法間の精度比較が行われている。\cite{sakurai1990}や\cite{ota2006}のレビュー論文は、そのような数々の利益予測の研究に関する文献についてまとめている。アメリカの利益予測の研究に関して、\cite{sakurai1990}は以下のようにまとめている。まずEPSを予測する伝統的な時系列モデルについて、年次EPSはランダムウォークモデルによってうまく描写され、四半期EPSは\cite*{brown1979univariate}、\cite{griffin1977time}、\cite{foster1977quarterly}の3つのARIMAモデルによってうまく描写されるとしている。一方で、アナリスト予測と伝統的な時系列モデルによる予測の比較については、アナリストによる年次および四半期のEPS予測が伝統的な時系列モデルによる予測よりも正確であると述べている。その理由として、アナリストは広く最新な情報集合を予測に用いるからであるとしている。\cite{ota2006}では、日本の利益予測に関する研究の数が非常に少ないとしつつも、アメリカと同様な比較結果を得ているとしている。そして、時系列モデルによる予測に関しては、アナリスト予測との精度比較の明確な結論が出ていないにも拘わらず、最近の研究では時系列モデルによる予測よりもアナリスト予測を用いる方が市場の期待利益として適切であると暗黙裡に見なされており、時系列モデル予測の研究は、現在では衰退していると述べている。

ここで注意するべき点として、上記で言及されているEPS予測精度の比較の研究で扱われている時系列モデルの多くは、あくまでも当時研究が盛んであった伝統的な単変量で線形の時系列モデルのことであり、代替的な多変量モデルや非線形モデルについては議論されていない。\cite{ota2006}は「ナイーブな時系列を用いた場合には人的な予測の方が精度が高いが、高度な時系列モデルを用いた場合には時系列モデルの予測の方が人的な予測よりも精度が高いといえる」と述べ、モデルの改善により統計的・機械的なEPS予測の精度は向上する余地があること示唆している。

近年、多くの学術分野で応用され成果を上げている予測モデルとして、機械学習アルゴリズムの1つであるニューラルネットワーク(Neural Network: NN)モデルが挙げられる。NNモデルは生物の神経細胞(ニューロン)の構造と機能をもとに考案された数学モデルであり、従来の統計モデルに比べて非線形で不定形な問題にうまく対処できることから、多数の分野での利用が増加している\citep*{tkavc2016artificial}。特に、\cite{hill1996neural}は、月次や四半期の時系列予測においてNNモデルの方が伝統的な統計モデルよりも正確な予測を与えるとし、時系列予測におけるNNモデルの有用性を示している。その理由として、NNはあらゆる関数形を近似できる普遍性定理(Universal Approximation Theorem)\citep{hornik1989multilayer}により、伝統的な線形統計モデルでは捉えられない時系列データの非線形性を捉え、予測モデルの関数形の誤特定を回避できるからであると述べている。また、\cite{hill1994artificial}は、予測の対象である時系列データが、i)財務的、ii)季節的、iii)非線形な特徴を有するとき、NNモデルによる予測は従来の線形時系列モデルよりも精度が高い傾向があると述べている。特に四半期EPSは上記の3つの特徴を有することも確認されている\citep*{hopwood1986univariate}。

そこで、\cite{callen1996neural}はニューヨーク株式市場の企業を対象に、単変量の四半期EPS予測におけるNNモデルと従来の統計的手法であるARIMAモデルとの精度を比較してNNの予測精度を検証したが、結果は予想に反してNNモデルによる予測がARIMAモデルによる予測よりも精度が低かった。そして、この研究ではNNの予測精度は文脈依存であると結論付けている。
% (Hillのディスポイント)

一方、会計学の研究では、企業利益の予測について、将来の利益を説明する変数を特定することに注目してきた。\cite*{lev1993fundamental}は、アナリストが有価証券の価値評価において有用であるとしている会計変数を調査し、それらの会計変数が将来の企業利益と関連があると述べている。言及された会計変数は以下のとおりである。

\begin{itemize}
\item 棚卸資産 (Inventories) \\
    売上原価の増加に対して過度な棚卸資産の増加は、売上高を増加させることが困難であることを示唆するため、ネガティブなシグナルとみなされる。さらに、棚卸資産が増加すると経営者は在庫を減らそうとするため、将来の利益が減少するシグナルになり得る。

\item 売掛金 (Accounts receivable) \\
    売上高に対して過度な売掛金の増加は、企業の製品販売が困難な状態にあることや、賃倒引当金の増加などを意味し、将来の利益が減少するシグナルになり得る。

\item 資本的支出 (Capital expenditures) \\
    資本的支出の過度な減少は、以前の投資水準を維持するための現在および将来のキャッシュフローが十分でないという経営者の懸念を意味する。このように一般的に資本的支出の減少は、短期的な経営志向とみなされ、将来の利益が減少するシグナルになり得る。

\item 売上総利益 (Gross margin) \\
    売上総利益は企業の競争の激しさや営業レバレッジなどの要因を捉え、これが企業の長期的なパフォーマンスに影響を与える。したがって、売上総利益は企業の利益の持続性や企業価値に関して有益な情報をもち、売上高に対して過度な売上総利益の減少は、将来の利益が減少するシグナルになり得る。

\item 販売費および一般管理費 (Selling and administrative expenses) \\
    ほとんどの場合、販売費および一般管理費は一定であるため、売上高に対して過度な販売費および一般管理費の増加は、コストコントロールの喪失や異常な販売努力を示唆し、将来の利益が減少するシグナルになり得る。

\item 実効税率 (Effective tax rate) \\
    法定税率の変更に依らない企業の実効税率の大幅な変化は、一般的には一時的なものとして捉えられる。したがって、過度な実効税率の低下は将来の利益が減少するシグナルになり得る。

\item 労働力 (Labor force) \\
    一般的に労働力の削減の発表に対してアナリストは好意的な反応を示す。したがって、過度な労働力の増加は将来の利益が減少するシグナルになり得る。
\end{itemize}

\cite*{abarbanell1997fundamental}では、上記の会計変数を「ファンダメンタル会計変数」とし、ファンダメンタル会計変数が将来のEPSの変化を説明するかどうかについて検証している。分析の結果、ファンダメンタル会計変数と将来のEPSの変化の間に強い関係が確認され、ファンダメンタル会計変数に含まれる会計情報は、将来のEPSに対して予測能力を持つと述べている。

これを受け\cite{zhang2004neural}は、\cite{callen1996neural}の単変量NNモデルによる四半期EPS予測の研究を発展させる形で、NNモデルにファンダメンタル会計変数を反映させた多変量NNモデルによる四半期EPS予測を行った。この研究では、単変量線形モデル、多変量線形モデル、単変量NNモデル、多変量NNモデルの4つの精度比較を行い、結果として、NNモデルは線形モデルよりもうまくファンダメンタル会計変数の情報を反映し、より精度の高いEPSの予測値を与えた。その後、様々な国のサンプルでEPS予測におけるNNモデルの有用性を示した研究が行われている。\cite*{cao2009forecasting} は中国の上海証券取引所と深セン証券取引所の上場企業、\cite{etemadi2015earnings}はイランのテヘラン証券取引所の上場企業を対象に、ファンダメンタル会計変数を反映させたNNモデルによるEPS予測を行っており、いずれも高い精度の予測を与える結果を得ている。

このように近年の四半期EPS予測の研究では多変量NNモデルが盛んに用いられているが、機械学習アルゴリズムの1つであるNNモデルだけが注目され他の機械学習アルゴリズムを用いた研究は限られている。これはEPS予測の文脈に限らず、他の時系列予測研究でもNNモデルのみに着目している傾向がある\citep{ahmed2010empirical}。一方、NNモデル以外の機械学習アルゴリズムが四半期EPS予測において成果を上げられる可能性も十分にある。代表的な機械学習アルゴリズムとして、罰則回帰モデルやランダムフォレスト回帰モデルが挙げられる\citep{hastie2009esl}。罰則回帰モデルは、高次元データに対して変数選択・係数縮小を行うことで多数の説明変数から目的変数を予測する情報を抽出し、精度の高い予測を行うことができるため、四半期EPSの多変量予測において有用であると考えられる。また、ノンパラメトリックで非線形なランダムフォレスト回帰モデル\citep{breiman2001random}も、NNモデルとは異なったアルゴリズムで四半期EPSデータの非線形性を捉えることができると考えられる。\cite*{cao2020fundamental}は年次ではあるものの、これらの代表的な機械学習アルゴリズムを用いたEPS予測をしており、ベンチマークであるランダムウォーク(Random Walk: RW)モデルよりも精度の高い予測を与える結果となっている。

% (Hill et al のNNディスも少し入れる)

以上の過去の研究を踏まえ、現状の日本のEPS予測における「時系列モデルが古典的な手法にとどまっていること」と「時系列モデルと人的な予測の優劣の曖昧さ」の2つの課題に対し、本稿は機械学習アルゴリズム(NNモデル、罰則回帰モデル、ランダムフォレスト回帰モデル)にファンダメンタル会計変数を含めて日本企業の四半期EPSの予測を行い、さらに時系列モデルとアナリストのEPS予測精度を比較し、予測手法間の精度の優劣を明らかにする。

\part{データ}

\section{サンプルデータ} label{sec:sample}

日本の四半期報告制度は比較的新しく、2007年の企業会計基準委員会(ASBJ)による企業会計基準第12号「四半期財務諸表に関する会計基準」及び企業会計基準適用指針第14号「四半期財務諸表に関する会計基準の適用指針」の公表以降、上場企業の四半期報告書の提出が義務付けられた。\footnote{2011年に企業会計基準委員会(ASBJ)は改正企業会計基準第12号「四半期財務諸表に関する会計基準」及び改正企業会計基準適用指針第14号「四半期財務諸表に関する会計基準の適用指針」等の公表をしている。この四半期報告制度の改正では財務諸表作成者の作成負担を考慮し、いくつかの四半期情報の開示を義務ではなく任意としている。それに伴い、四半期報告制度の改正以降、資本的支出と期末従業員数の観測される頻度が減り、欠損が多く見られる。\cite{zhang2004neural}は四半期単位で欠損している資本的支出と期末従業員数について、資本的支出は毎四半期均等であるとし、期末従業員数は前期の値を維持すると仮定して、欠損値を補填している。本稿でもこの方法に倣って資本的支出と期末従業員数の欠損処理を行うこととする。}

これにより、四半期データを分析の単位とする本稿では、サンプル期間を四半期報告制度が適用された2008年度(2008年4月1日)から現在2020年度(2021年3月31日)までの計52四半期とする。また、本稿の分析対象企業(サンプル企業)を、サンプル期間において以下の基準で選択する。

\begin{itemize}
  \item 東京証券取引所一部上場企業
  \item 3月決算企業
  \item 一般事業者(「銀行業」、「証券、商品先物取引業」、「保険業」、「その他金融業」を除く)
  \item 各四半期の中間月末(5月末, 8月末, 11月末, 2月末)までに前四半期決算を発表している企業\footnote{IBES予測及びポートフォリオ構築のタイミングをそろえるため。}
\end{itemize}

四半期EPS(3ヶ月)およびファンダメンタル会計変数の算出に必要な四半期会計データは「日経NEEDS-FinancialQUEST」から収集している。結果、1,003社、延べ 1,003社 × 52四半期 = 52,156個の企業四半期が最終サンプルである。表\ref{tab:ind}はサンプル企業の所属業種の割合を示している。なお、所属業種は証券コード協議会の中分類(全33種)に基づいている。

\begin{table}
  \centering
  \caption{業種(証券コード協議会中分類33種)}
  \label{tab:ind}
  \scalebox{0.7}[0.7]{
    \input{./img/ind_cat_table.tex}
  }
\end{table}

\section{目的変数}

予測の対象となる四半期1株あたり利益(四半期EPS)は以下のように定義される。

\begin{equation}
  \begin{split}
    Y &= \text{四半期 1株あたり利益} \\
    &= \frac{普通株式に係る四半期当期純利益}{普通株式の期中加重平均株式数} \\
    &= \frac{損益計算書上の四半期当期純利益-普通株式に帰属しない金額}{普通株式の期中加重平均発行済株式数 - 普通株式の期中加重平均自己株式数} \\  
  \end{split}
\end{equation}

\section{説明変数}

単変量モデルによる四半期EPS予測は、過去の四半期EPSのみを説明変数として用いる。一方、多変量モデルによって四半期EPSを予測する場合は、過去の四半期EPSに加えて、\cite{lev1993fundamental}や\cite{abarbanell1997fundamental}が企業の将来のEPSに対して予測能力を持つと言及しているファンダメンタル会計変数を説明変数として用いる。本稿では、ファンダメンタル会計変数を実際に四半期EPS予測に用いた\cite{zhang2004neural}に倣って以下のように7つのファンダメンタル会計変数を定義する。

\begin{equation}
  \begin{split}
    INV &= \frac{棚卸資産(円)}{普通株式の期中加重平均株式数} \\
    AR &= \frac{売掛金(円)}{普通株式の期中加重平均株式数} \\
    CAPX &= \frac{資本的支出(円)}{普通株式の期中加重平均株式数} \\
    GM &= \frac{売上総利益(円)}{普通株式の期中加重平均株式数} \\
    SA &= \frac{販売費及び一般管理費(円)}{普通株式の期中加重平均株式数} \\
    ETR &= \frac{法人税(円)}{税引前利益(円)} \\
    LF &= \log{\left(\frac{売上高(円)}{従業員数(人)}\right)} \\
  \end{split}
\end{equation}

多変量モデルによる予測では四半期EPSとファンダメンタル会計変数の4期までのラグを説明変数として用いる。表\ref{tab:summary}は予測に用いた変数の記述統計を示している。

\begin{table}
  \centering
  \caption{変数の記述統計量}
  \label{tab:summary}
  \scalebox{0.7}[0.7]{
    \input{./img/var_sum_table.tex}
  }
\end{table}

% GM, SA, ETRが負になる説明
    
\part{予測モデル}

\section{予測のデザイン}

本稿では、サンプル企業1,020社について、それぞれ1社ごとに1四半期先予測を12期(3年)分行う。まず、ある企業の全52四半期サンプル期間\footnote{実際のモデル推定では説明変数にラグ変数を含める。したがって利用できるサンプル期間は$52 - ラグの次数 $である。モデルのデザインによってラグの次数は異なるため、利用できる訓練データの長さもモデルによって異なる。}をもとに、1つあたり長さ41期のローリングサンプル(rolling sample)を12個形成する。次に、1つのローリングサンプルを、過去40期の訓練データ(training data, in-sample)と最新1期のテストデータ(test data, out-of-sample)に分ける。そして訓練データを用いてモデルを推定し、テストデータと同じ期にあたる1期先の予測を行う。これを12個のローリングサンプルで繰り返すことによって、ある企業の1四半期先予測が12期分得られる。

つまり具体的には、ある企業の全52四半期サンプル期間 $(Data_{\text{2008Q1}}, Data_{\text{2008Q2}}, \cdots, Data_{\text{2020Q4}})$ から12個のローリングサンプルを作り、1つ目の長さ41期のローリングサンプル $(Data_{\text{2008Q1}}, Data_{\text{2008Q2}}, \cdots, Data_{\text{2017Q4}}, Data_{\text{2018Q1}})$ を長さ40期の訓練データ $(Data_{\text{2008Q1}}, Data_{\text{2008Q2}}, \cdots, Data_{\text{2017Q4}})$ と長さ1期のテストデータ ($Data_{\text{2018Q1}})$ に分け、訓練データを用いてモデルを推定し、テストデータの説明変数を代入して訓練データの1期先の四半期EPS $y_{2018Q1}$ の予測値 $\hat{y}_{2018Q1}$ を求める。2つ目のローリングサンプル $(Data_{\text{2008Q2}}, Data_{\text{2008Q3}}, \cdots, Data_{\text{2018Q1}}, Data_{\text{2018Q2}})$ も同様に 訓練データ $(Data_{\text{2008Q2}}, Data_{\text{2008Q3}}, \cdots, Data_{\text{2018Q1}})$ を用いて1期先の四半期EPSの予測値 $\hat{y}_{2018Q2}$ を求める。同様に他のローリングサンプルに対しても、それぞれ同じモデルを異なる期間の訓練データで推定し、1企業につき予測期間は2018年度第1四半期~2020年度第4四半期の12期となり、1四半期先予測値系列 $(\hat{y}_{2018Q1}, \hat{y}_{2018Q2}, \cdots, \hat{y}_{2020Q4})$ が得られる。この予測プロセスを全サンプル企業1,020社に対して行うことで、最終的に$12期 \times 1,003社 = 12,036個$の四半期EPS予測値が各予測手法から算出される。

図\ref{fig:rolling}は本稿のローリングサンプルによる1期先予測の概要を示している。

\begin{figure}
  \centering
  \caption{ローリングサンプルのイメージ}
  \label{fig:rolling}
  \includegraphics[width=12cm]{./img/_rolling_sample.png}
\end{figure}
% <!-- blender使って、企業の軸も入れて3Dにするとかっこいい? -->

\section{伝統的時系列モデル}

\subsection{ランダムウォークモデル}

$Y_t$をある企業におけるt期の四半期EPSとすると、もっとも単純な単変量モデルであるランダムウォークモデルは次のとおりである。

\begin{equation}
  \begin{split}
    & Y_t = Y_{t-1} + \epsilon_t \\
    & \hat{y}_t^{RW} = Y_{t-1} \\
  \end{split}
\end{equation}        

%     \\
%     & ただし, \epsilon_t は全ての時点 t において \\
%     & E[\epsilon_t] = 0 \\
%     & E[\epsilon_t \epsilon_{t-k}] = \left\{
%         \begin{array}{ll}
%         \sigma^2 & k=0 \\
%         0 & k \neq 0
% \end{array}\right. \\
%     & を満たすホワイトノイズである. \\
%     \\

ただし, $\epsilon_t$は全ての時点tにおいて
\begin{equation}
  \begin{split}
    & E[\epsilon_t] = 0 \\
    & E[\epsilon_t \epsilon_{t-k}] = \left\{
      \begin{array}{ll}
        \sigma^2 & k=0 \\
        0 & k \neq 0
      \end{array}\right. \\
  \end{split}
\end{equation}    

を満たすホワイトノイズである.

一方、四半期EPS時系列には１年単位での季節的変動パターンがあると考えられる。そこでランダムウォーク過程を1四半期単位ではなく、1会計年度単位(4四半期)であると考慮した季節ランダムウォークモデルが次のとおりである。

\begin{equation}
  \begin{split}
    & Y_t = Y_{t-4} + \epsilon_t \\
    & \hat{y}_t^{SRW} = Y_{t-4} \\
  \end{split}
\end{equation} 

ランダムウォークモデルは前四半期の実績値を、季節ランダムウォークモデルは前年同四半期の実績値を予測値とするモデルであり、どちらも実際の予測においてパラメータを推定する工程がない単純なモデルである。そこで、本稿ではランダムウォークモデル及び季節ランダムウォークモデルを他の予測に対するベンチマークとして用いる。

\subsection{ARIMAモデル}

従来の四半期EPSを予測する単変量線形時系列モデルとして、自己回帰和分移動平均(AutoRegressive Integrated Moving Average: ARIMA)モデル\citep{box2015time}\footnote{ARIMAモデルは提唱者の名前からBox-Jenkinsモデルとも呼ばれる。}、特にデータの季節性にも対応できるように一般化した季節自己回帰和分移動平均(Seasonal AutoRegressive Integrated Moving Average: SARIMA)モデルを用いる。$B^nY_t = y_{t-n}$ と定義されるような$B$(backshift operator)を導入すると、SARIMAモデルの一般形は以下のとおりである。\footnote{定数項$\theta_{\mu}=(1-\phi_1-\cdots-\phi_p)\mu$は階差をとれば0となるため、通常の取り扱いに従って0としている。}

\begin{equation}
  \begin{split}
    \phi_p(B)\Phi_{P}(B)(1-B)^d(1-B^s)^DY_t &= \theta_q(B)\Theta_Q(B^s)\epsilon_t
  \end{split}
\end{equation}

ただし、
\begin{equation}
  \begin{split}
    p &: トレンドの自己回帰過程の階数 \\
    d &: トレンド階差の次数 \\
    q &: トレンドの移動平均過程の階数 \\
    P &: 季節変動の自己回帰過程の階数 \\
    D &: 季節階差の次数 \\
    Q &: 季節変動の移動平均過程の階数 \\
    s &: 季節変動の周期 \\
    \phi_p(B) &= (1 - \phi_1B - \cdots - \phi_pB^p) \\
    \theta_q(B) &= (1 - \theta_1B - \cdots - \theta_qB^q) \\
    \Phi_P(B^s) &= (1 - \Phi_1B^s - \cdots - \Phi_PB^{sP}) \\
    \Theta_Q(B^s) &= (1 - \Theta_1B^s - \cdots - \Theta_QB^{sQ}) \\
  \end{split}
\end{equation}

通常、SARIMAモデルは$(p, d, q) \times (P, D, Q)$の値の組み合わせをBox-Jenkins法によってデータごとに選定し、モデルの構築を行う。一方、これまでの四半期EPSの時系列予測の分野では全ての企業に適合するSARIMAモデルが探求され、次の3つのSARIMAモデル\citep*{foster1977quarterly, griffin1977time, brown1979univariate}があらゆる企業の四半期EPSの時系列特性を描写するモデルであるとされている。\footnote{先行研究では、企業ごとにモデルを構築するよりも、企業で共通の構築で予測したほうが全体として予測のパフォーマンスが良いと示されている。}

\cite{foster1977quarterly} $: (p, d, q) \times (P, D, Q)_s = (1, 0, 0) \times (0, 1, 0)_4$

\begin{equation}
  \begin{split}
    % \text{ Foster (1977) } &: (p, d, q) \times (P, D, Q)_s = (1, 0, 0) \times (0, 1, 0)_4 \\
    Y_t &= Y_{t-4} + \phi_1(Y_{t-1} - Y_{t-5}) + \epsilon_t \\
    \hat{y}_t^{ARIMA-F} &= Y_{t-4} + \phi_1(Y_{t-1} - Y_{t-5}) + \delta \\
  \end{split}
\end{equation}

\cite{griffin1977time} $: (p, d, q) \times (P, D, Q)_s = (0, 1, 1) \times (0, 1, 1)_4$

\begin{equation}
  \begin{split}
    Y_t &= Y_{t-4} + (Y_{t-1} - Y_{t-5}) - \theta_1a_{t-1} - \Theta_1a_{t-4} + \theta_1\Theta_1a_{t-5} + \epsilon_t \\
    \hat{y}_t^{ARIMA-G} &= Y_{t-4} + (Y_{t-1} - Y_{t-5}) - \theta_1a_{t-1} - \Theta_1a_{t-4} + \theta_1\Theta_1a_{t-5} + \delta \\
  \end{split}
\end{equation}

\cite*{brown1979univariate} $: (p, d, q) \times (P, D, Q)_s = (1, 0, 0) \times (0, 1, 1)_4$

\begin{equation}
  \begin{split}    
    Y_t &= Y_{t-4} + \phi_1(Y_{t-1}-Y_{t-5}) - \Theta_1a_{t-4} + \epsilon_t \\
    \hat{y}_t^{ARIMA-BR} &= Y_{t-4} + \phi_1(Y_{t-1}-Y_{t-5}) - \Theta_1a_{t-4} + \delta \\
    \\
  \end{split}
\end{equation}

ただし, $\delta$はSARIMAモデルの定数項.

本稿では先行研究に倣い、特に支持されてきたこの3つのモデルを単変量線形時系列モデルとして用いることとする。

\subsection{多変量線形モデル}

ファンダメンタル会計変数が将来の四半期EPSを線形に説明するかどうかについて確かめるため、\cite*{lev1993fundamental}、\cite*{abarbanell1997fundamental}、\cite*{lorek1996multivariate}の研究で用いられているモデルを基に、以下のような多変量線形回帰モデルを考える。

\begin{equation}
  \begin{split}
    \label{eq:ols1}
    \hat{y}_t^{OLS-1} = \beta_0 + \beta_1Y_{t-1} + \beta_2Y_{t-4} 
    &+ \beta_3INV_{t-1} + \beta_4AR_{t-1} + \beta_5CAPX_{t-1} \\
    &+ \beta_6GM_{t-1} + \beta_7SA_{t-1} + \beta_8ETR_{t-1} + \beta_9LF_{t-1} \\
  \end{split}
\end{equation}

\begin{equation}
  \begin{split}
    \label{eq:ols2}
    \hat{y}_t^{OLS-2} = \beta_0 + \beta_1Y_{t-1} + \beta_2Y_{t-4} 
    &+ \beta_3INV_{t-4} + \beta_4AR_{t-4} + \beta_5CAPX_{t-4} \\
    &+ \beta_6GM_{t-4} + \beta_7SA_{t-4} + \beta_8ETR_{t-4} + \beta_9LF_{t-4} \\
  \end{split}
\end{equation}

2つのモデルはどちらも、四半期EPSの1四半期前ラグ$Y_{t-1}$と4四半期前ラグ$Y_{t-4}$が自己回帰的な説明変数として含まれている。両者の違いとしてはファンダメンタル会計変数のラグの次数にあり、(\ref{eq:ols1})のモデルではファンダメンタル会計変数の1四半期前ラグを、(\ref{eq:ols2})のモデルでは季節性を考慮してファンダメンタル会計変数の4四半期前ラグをモデルの説明変数として含めている。一方、Cao and Parry (2009) は後述する機械学習モデルと利用できる情報の公平性に保つため、以下のように四半期EPSとファンダメンタル会計変数のラグ変数を1四半期前、2四半期前、3四半期前、4四半期前すべて含めた多変量線形回帰モデルを推定している。

\begin{equation}
  \begin{split}
    \label{eq:ols3}
    \hat{y}_t^{OLS-3} = \beta_0 + \sum^{4}_{\tau=1} \left( \beta_{1\tau}Y_{t-\tau} 
    + \beta_{2\tau}INV_{t-\tau} + \beta_{3\tau}AR_{t-\tau} + \beta_{4\tau}CAPX_{t-\tau} \right. \\
    \left. + \beta_{5\tau}GM_{t-\tau} + \beta_{6\tau}SA_{t-\tau} + \beta_{7\tau}ETR_{t-\tau} + \beta_{8\tau}LF_{t-\tau} \right) \\
  \end{split}
\end{equation}

以上のファンダメンタル会計変数を説明変数として用いた3つの多変量線形回帰モデルを多変量モデルのベンチマークとして、他の手法による多変量予測と比較する。なお、これらのモデルのパラメータは最小二乗法を用いてを推定する。

\section{機械学習モデル}

% 金融データは高次元、7変数しかもラグ、普通のモデルは変数多いと精度下がる。機械学習で次元削減。
% 金融データは非線形。非線形なモデル2つ。AnnとノンパラなRF

ここでは、本稿で用いる機械学習的手法について紹介する。なお、以下より共通して時点tの説明変数ベクトル$\bm{X}_t$について、単変量モデルでは目的変数である四半期EPS($Y_t$)のラグのみを用いてモデル構築を行う。

\begin{equation}
  \begin{split}
    \bm{X}_t &= (X_{t1}, \cdots ,X_{tk}) \\
    &= (Y_{t-1}, Y_{t-2}, Y_{t-3}, Y_{t-4}) \\
  \end{split}
\end{equation}

また、多変量モデルでは四半期EPS($Y_t$)のラグに加え、ファンダメンタル会計変数のラグも含めてモデルを構築する。

\begin{equation}
  \begin{split}
    \bm{X}_t = (&X_{t1}, \cdots ,X_{tk}) \\ 
    =(&Y_{t-1}, Y_{t-2}, Y_{t-3}, Y_{t-4}, \\
    & INV_{t-1}, INV_{t-2}, INV_{t-3}, INV_{t-4}, \\
    & AR_{t-1}, AR_{t-2}, AR_{t-3}, AR_{t-4}, \\
    & CAPX_{t-1}, CAPX_{t-2}, CAPX_{t-3}, CAPX_{t-4}, \\
    & GM_{t-1}, GM_{t-2}, GM_{t-3}, GM_{t-4}, \\
    & SA_{t-1}, SA_{t-2}, SA_{t-3}, SA_{t-4}, \\
    & ETR_{t-1}, ETR_{t-2}, ETR_{t-3}, ETR_{t-4}, \\ 
    & LF_{t-1}, LF_{t-2}, LF_{t-3}, LF_{t-4}) \\
  \end{split}
\end{equation}

としてモデルを構築する。

\subsection{罰則回帰モデル}

説明変数間に複数の強い相関が存在する場合、線形回帰モデルの最小二乗推定量の分散は大きくなる。そして高分散(high variance)により係数の推定値が極端な値をとると、in-sampleでの予測精度は高くても、out-of-sampleにおける予測精度が低くなる恐れがある。このように予測モデルがin-sampleデータの規則性のみを捉えてしまい、out-of-sampleを含めたデータ全体に対して汎化できていないことを過学習(overfitting)という。

線形回帰モデルの係数の推定値が極端な値をとることに起因する過学習を防ぐために、係数の大きさに罰則を与えて推定する手法が罰則回帰モデル(penalized regression model)である\footnote{罰則回帰モデルの詳細については、\cite*{hoerl1970ridge, tibshirani1996regression, zou2005regularization}などを参照されたい。}。罰則回帰モデルは、その罰則の与え方によって推定で最小化する目的関数が異なる。本稿では罰則回帰モデルのうち、代表的なRidge回帰モデル、LASSO回帰モデル、Elastic Net回帰モデルの3つを用いる。

Ridge回帰モデルの係数の推定式は次のとおりである。

\begin{equation} \label{eq:ridge}
  \begin{split}
    \hat{\bm{\beta}}^{Ridge} = \argmin_{\bm{\beta}}\left\{ \sum_{t=1}^{T} \left( Y_t - \beta_0 - \sum_{j=1}^{k} \beta_{j} X_{tj} \right)^2 + \lambda \sum_{j=1}^{k} \beta_{j}^{2} \right\}
  \end{split}
\end{equation}

ここで、$\lambda \geq 0$は罰則の強さを調節するパラメータであり、モデル推定の枠組みの中で決定されないパラメータ(ハイパーパラメータ)である。ハイパーパラメータの値はデータに応じて指定する必要があり、ハイパーパラメータの選択方法の詳細については\ref{sec:hyparam}節で説明する。(\ref{eq:ridge})式で示されるように、Ridge回帰モデルでは目的関数に係数の二乗和が含まれており、係数が過大な値をとることを防ぐ構造となっている。したがってRidge回帰モデルは予測情報を持たない説明変数に対して係数縮小(parameter shrinkage)し、モデルの過学習を防ぐ。

LASSO(Least Absolute Shrinkage and Selection Operator)回帰モデルの係数の推定式は次のとおりである。

\begin{equation} \label{eq:lasso}
  \begin{split}
    \hat{\bm{\beta}}^{LASSO} = \argmin_{\bm{\beta}}\left\{ \sum_{t=1}^{T} \left( Y_t - \beta_0 - \sum_{j=1}^{k} \beta_{j} X_{tj} \right)^2 + \lambda \sum_{j=1}^{k} \left|\beta_{j}\right| \right\}
  \end{split}
\end{equation}

LASSO回帰モデルは、Ridge回帰モデルと同様、目的関数にパラメータのサイズに関する罰則項が含まれているが、罰則として係数の絶対値の和を用いている点がRidge回帰モデルとの違いである。この罰則の与え方により、予測情報を持たない説明変数の係数が丁度0となるスパース推定が行われる。つまり、LASSO回帰モデルを推定することで変数選択が行われる。

Elastic Net回帰モデルの係数の推定式は次のとおりである。

\begin{equation}
  \begin{split}
    \hat{\bm{\beta}}^{EN} = \argmin_{\bm{\beta}}\left\{ \sum_{t=1}^{T} \left( Y_t - \beta_0 - \sum_{j=1}^{k} \beta_{j} X_{tj} \right)^2 + 
    \lambda \left\{ 
      \left( 1 - \alpha \right) \sum_{j=1}^{k} \beta_{j}^2 + 
      \alpha \sum_{j=1}^{k} \left|\beta_{j}\right| 
      \right\} 
    \right\}
  \end{split}
\end{equation}

Elastic Net回帰モデルは、Ridge回帰モデルとLASSO回帰モデル両方の罰則項を利用する構造となっている。$\alpha$はLASSO回帰モデルの罰則の影響の割合を調節するハイパーパラメータであり、罰則の強さを調節するハイパーパラメータ$\lambda$と併せて指定する必要がある。

なお、それぞれの罰則回帰モデルの予測値は次のとおりである。

\begin{equation}
  \begin{split}
    \hat{y}_t^{Ridge} &= \beta_0^{Ridge} + \sum_{j=1}^{k} \beta_{j}^{Ridge} x_{tj} \\
    \hat{y}_t^{LASSO} &= \beta_0^{LASSO} + \sum_{j=1}^{k} \beta_{j}^{LASSO} x_{tj} \\
    \hat{y}_t^{EN} &= \beta_0^{EN} + \sum_{j=1}^{k} \beta_{j}^{EN} x_{tj} \\
  \end{split}
\end{equation}

\subsection{ランダムフォレスト回帰モデル}

ランダムフォレスト\citep{breiman2001random}は、決定木を弱学習器とするアンサンブル学習である。弱学習器とはそれ単独で用いると精度が低いような予測モデルであり、アンサンブル学習はその弱学習器を複数推定し、組み合わせることで予測精度の向上を図る手法である。弱学習器となる決定木は、ある変数のある閾値でデータを2分割し、この分割を繰り返すことで作成される。単独の決定木による予測値は、予測サンプルの説明変数をもとに作成された木の分岐を辿り、到達した末端ノードに属するサンプルの目的変数の平均値である。ランダムフォレスト回帰モデルでは、元のデータセットから標本及び変数を無作為に復元抽出した複数のサブデータセットを構築し(ブートストラップサンプリング)、それをもとに弱学習器である決定木を複数推定する。そして各決定木の予測値の平均値が最終的なランダムフォレスト回帰モデルの予測値となる。

% ランダムフォレストのイラスト?https://www.stats-guild.com/analytics/12543

決定木の数を$M$とし、$m=1, \cdots M$番目の決定木のt時点における予測値を$\textit{Tree}_m(\bm{X}_t)$とすると、ランダムフォレスト回帰モデルの予測値は以下のように表される。

\begin{equation}
  \begin{split}
    \hat{y}_t^{RF} = \frac{1}{M} \sum_{m=1}^{M} \textit{Tree}_m(\bm{X}_t)
  \end{split}
\end{equation}

なお、ランダムフォレスト回帰モデルの複雑さを調節する決定木の数や決定木の分岐の回数(木の深さ)はハイパーパラメータであり、分析者が指定する必要がある。

ランダムフォレスト回帰モデルは、ノンパラメトリックで非線形なモデルであり、説明変数と目的変数間に非線形な関係がある場合でも優れた予測が得られると考えられる。また、ブートストラップをもとに相関のない複数の決定木を推定して各決定木の予測値の平均を用いて予測を行うため、最終的な予測値の分散は小さく、予測の汎化性能が高まる性質を持つ。

\subsection{ニューラルネットワークモデル}

ニューラルネットワーク(Neural Network: NN)モデルについて述べる。まずNNの構造の最小単位であるパーセプトロン(perceptron)について考える。$\bm{X_t}=(X_{t1}, \cdots, X_{tk})$を入力ベクトルとする。$(w_1, \cdots, w_k)$は入力ベクトルの要素それぞれに対応する重み(weight)であり、スカラー値$b$はバイアス(bias)という。パーセプトロンではまず始めに$\bm{X_t}=(X_{t1}, \cdots, X_{tk})$と$(w_1, \cdots, w_k)$の内積と$b$の和であるプレアクティベーション(pre-activation)$z$を計算する。

\begin{equation}
  \begin{split}
    z = w_1 X_{t1} + \cdots + w_k X_{tk} + b
  \end{split}
\end{equation}

次に$z$は非線形な関数である活性化関数(activation function) $\phi(\cdot)$ に渡され、アクティベーション(activation)$a$として出力される。

\begin{equation}
  \begin{split}
    a = \phi(z)
  \end{split}
\end{equation}

以上がNNのパーセプトロンの構造であり、まとめると以下の式で表される。

\begin{equation}
  \begin{split}
    a = \phi(w_1 X_{t1} + \cdots + w_k X_{tk} + b)
  \end{split}
\end{equation}

このパーセプトロンを複数組み合わせることで、NNが構成される。

NNと一口に言っても様々な構造をもつ多くの種類がある。NNの1種である順伝播型ニューラルネットワーク(Feed-forward Neural Network: FNN)はNNのなかでも基本的な構造を持ち、全てのパーセプトロンが結合した無閉路グラフ(acyclic graph)で表現されすべての計算が逐次的に行われる。FNNの最も代表的なネットワークは多層パーセプトロン(multilayer perceptron: MLP)であり、図\ref{fig:perceptron}のように表される。

\begin{figure}
  \centering
  \caption{パーセプトロンのイメージ}
  \label{fig:perceptron}
  \includegraphics[width=7cm]{./img/_ann_unit.png}
\end{figure}

MLPの特徴として、横のつながりのパーセプトロンをそれぞれ層としてまとめると少なくとも3つ以上の層から構成される。またMLPはネットワークの全てのパーセプトロンが次の層に含まれる全てのパーセプトロンとそれぞれ結合している(fully connected)。ネットワークの最初の層は入力層(input layer)といい入力される特徴量がここにあたる。最後の層は出力層(output layer)といいネットワークが出力する値であり、出力層のアクティベーションは予測値を表す。この2つを除いた間の層は全て隠れ層(hidden layer)といい、MLPの多層構造を作る。

例えば、入力層と1層の隠れ層、出力層から成る3層パーセプトロンを定式化してみる。まず、隠れ層のアクティベーションをベクトル$(H_{t1}, \cdots, H_{tL})$とする(activation vector)。ただし、$L$は隠れ層に含まれるパーセプトロンの数である。また、隠れ層の活性関数を $\phi^{(1)}(\cdot)$ とし、隠れ層のバイアス項を$(b^{(1)}_1, \cdots, b^{(1)}_L)$とすると、隠れ層のアクティベーションは以下のように表される。

\begin{equation}
  \begin{split}
    H_{t1} &= \phi^{(1)}(w^{(1)}_{11} X_{t1} + w^{(1)}_{21} X_{t2} + \cdots + w^{(1)}_{k1} X_{tk} + b^{(1)}_1) \\
    H_{t2} &= \phi^{(1)}(w^{(1)}_{12} X_{t1} + w^{(1)}_{22} X_{t2} + \cdots + w^{(1)}_{k2} X_{tk} + b^{(1)}_2) \\
    \vdots \\
    H_{tL} &= \phi^{(1)}(w^{(1)}_{1L} X_{t1} + w^{(1)}_{2L} X_{t2} + \cdots + w^{(1)}_{kL} X_{tk} + b^{(1)}_L) \\
  \end{split}
\end{equation}

 次に、出力層について考える。予測する変数は本稿では1次元であるため、出力層のアクティベーションはスカラー$Y$となる。出力層の活性関数を$\phi^{(2)}(\cdot)$とし、バイアス項を$b^{(2)}$とすると、出力層のアクティベーション(または予測値)は以下のように表される。図\ref{fig:mlp}はMLPのイメージを表している。

\begin{equation}
  \begin{split}
    Y_t = \phi^{(2)}(w^{(2)}_{1} H_{t1} + w^{(2)}_{2} H_{t2} + \cdots + w^{(2)}_{L} H_{tL} + b^{(2)})
  \end{split}
\end{equation}

\begin{figure}
  \centering
  \caption{パーセプトロンのイメージ}
  \label{fig:mlp}
  \includegraphics[width=7cm]{./img/_ann_mlp.png}
\end{figure}

このように、MLPは線形結合モデルを非線形変換したものの繰り返しであることがわかる。このMLPの隠れ層の数を増やすことで、ネットワークをより深くすることができ、深層ニューラルネットワークが構築できる。一方、\cite{qi1999nonlinear}は隠れ層のパーセプトロン数が十分であれば、隠れ層が1つで、隠れ層の活性化関数にロジスティック関数、出力層の活性化関数に恒等関数を用いた3層パーセプトロンは、あらゆる連続関数を近似できると述べている。そこで本稿は、\cite{callen1996neural}や\cite{zhang2004neural}と同様に以下のような3層パーセプトロンを用いる。

\begin{equation}
  \begin{split}
    \hat{y}_t^{NN} 
    &= f({\bm{X}_t, \alpha, \beta}) \\
    &= \sum^{L}_{l=1} \left(\alpha_0 + \alpha_l H_{tl} \right) \\
    &= \sum^{L}_{l=1} \left\{ \alpha_0 + \alpha_l \textit{logistic} \left(\sum^{k}_{j=1} \left(\beta_{0l} + \beta_{jl} X_{tj} \right) \right) \right\} \\
  \end{split}
\end{equation}

ただし、

\begin{equation}
  \begin{split}
    Y_t &: 出力(目的変数) \\
    \bm{X}_t=(X_{t1}, \cdots, X_{tk}) &: 時点tの入力(説明変数)ベクトル \\
    X_{tk} &: k番目の入力(説明変数) \\
    \alpha_l &: 隠れ層のl番目のパーセプトロンと目的変数のウェイト(パラメータ) \\
    L &: 隠れ層のパーセプトロン数 \\
    \alpha_0 &: 出力層のバイアス(定数項) \\
    \beta_{jl} &: j番目の入力(説明変数)とl番目の隠れ層のパーセプトロンのウェイト(パラメータ) \\
    \beta_{0l} &: 隠れ層のl番目のパーセプトロンのバイアス(定数項) \\
    \textit{logistic}(\cdot) = \frac{\exp(\cdot)}{1 + \exp(\cdot)} &: ロジスティック関数
  \end{split}
\end{equation}

NNモデルの推定は誤差逆伝播法(Backward propagation algorithm)を用いてウェイトの勾配を計算し、勾配降下によって行う。なお、NNモデルの複雑さを調節する隠れ層のパーセプトロン数と、ウェイトの更新量の幅を調節する学習率はハイパーパラメータであり、分析者が指定する必要がある。

\section{ハイパーパラメータの選択} \label{sec:hyparam}

多くの機械学習アルゴリズムには、モデル推定の枠組みでは決定されない、分析者が指定する必要のあるハイパーパラメータが存在する。ハイパーパラメータの値が正しく設定できていないと、それをもとに推定されたモデルは過学習もしくは学習不足\footnote{過学習の反対語で、訓練データの規則性を十分とらえきれていないことを意味する。例えば、罰則付き回帰の罰則の強さを表す$\lambda$の値がデータに対して大きすぎる場合、係数の大きさに対する罰則が必要以上に強く、モデルがデータの規則性を受分に学習できない可能性が生じる。}となる恐れがあり、未知のデータに対して汎化性能を持たず、高い予測精度が期待できない。そこで本稿では適切なハイパーパラメータの値を設定するため、企業ごとにグリッドサーチを行う。

具体的には、ある1企業の12個のローリングサンプルそれぞれの訓練データのうち、最新時点のデータをあらたに検証データ(validation data)として分割する。例えば1つ目のローリングサンプル$(Data_{\text{2008Q1}}, Data_{\text{2008Q2}}, \cdots, Data_{\text{2017Q3}}, Data_{\text{2017Q4}}, Data_{\text{2018Q1}})$では、訓練データを$(Data_{\text{2008Q1}}, Data_{\text{2008Q2}}, \cdots, Data_{\text{2017Q3}})$, 検証データを$(Data_{\text{2017Q4}})$、テストデータを$(Data_{\text{2018Q1}})$として3つに分割する。この分割を12個のローリングサンプルに対して行い、12個の検証データ$(Data_{\text{2017Q4}}, \cdots , Data_{2020Q3})$を得る。次に、候補となるハイパーパラメータの組を設定し、全通りのハイパーパラメータをそれぞれ用いて訓練データのみをもとに12個のモデルを推定し、検証データの目的変数を予測する。そして、検証データに対する予測能力が最も高いハイパーパラメータの組合せを最適な設定であるとする。最終的には、最適なハイパーパラメータを用いて訓練データと検証データの両方をもとにモデルを推定し、テストデータの目的変数を予測する。図\ref{fig:hyparam_selection}は本稿におけるハイパーパラメータの選択のイメージを表している。

% なお、本稿で用いた各機械学習モデルのハイパーパラメータの候補はAppendixに記載している。

\begin{figure}
  \centering
  \caption{ハイパーパラメータ選択のイメージ}
  \label{fig:hyparam_selection}
  \includegraphics[width=12cm]{./img/_rolling_sample_val_i.png}
\end{figure}

\part{予測精度指標}

各モデルの四半期EPS予測の精度を測るために、以下の予測精度指標を用いる。

平均絶対誤差(Mean Absolute Error: MAE)

\begin{equation}
  \begin{split}
    \text{MAE} = \frac {1} {T} \sum^{T}_{t=1}\left| Y_t - \hat{Y}_t \right|
  \end{split}
\end{equation}

平均絶対誤差率(Mean Absolute Percentage Error: MAPE)

\begin{equation}
  \begin{split}
    \text{MAPE} = \frac {1} {T} \sum^{T}_{t=1}\left| \frac {(Y_t - \hat{Y}_t)} {Y_t} \right|
  \end{split}
\end{equation}

平均二乗誤差率(Mean Squared Percentage Error: MSPE)

\begin{equation}
  \begin{split}
    \text{MSPE} = \frac {1} {T} \sum^{T}_{i=1} \left( \frac { ( Y_t - \hat{Y}_t)} {Y_t} \right) ^2
  \end{split}
\end{equation}

ただし、$T$はテストデータの期間であり、本稿では12期間である。なお、絶対予測誤差率$ \left| \frac{Y_t -{\hat Y}_t}{Y_t} \right|$が1を超える予測サンプルについて、\cite*{brown1979univariate}、\cite*{lorek1996multivariate}、\cite{zhang2004neural}に倣い絶対予測誤差率の上界(Upper Bound)を1とし、この制約に基づいて算出した精度指標を報告することとする。また、そのような予測サンプルはLarge forecast errorサンプルとし、予測精度指標と併せてLarge forecast errorの割合も報告する。

上述の指標は異なる予測モデル間で予測精度を比較するために用いられる。一方、精度指標の値は本稿で用いているデータセットのみに由来しているため、精度指標の大小関係を比較するだけではモデルの精度の優劣を一般化することはできない。そこで、本稿では異なる2つの予測モデル間に統計的に有意な予測精度の差が存在するかどうかを検定するために、Diebold-Mariano(DM)検定\cite*{diebold2002comparing}を行う。

\part{予測結果}

\section{時系列モデル間の予測精度比較}

\begin{landscape}
\begin{table}
  % \centering
  \caption{統計的・機械的な手法による1期先四半期EPS予測の精度(1,003社平均)}
  \label{tab:acc}
  \scalebox{0.6}[0.6]{
    \input{./img/accuracy_edit.tex}
  }
\end{table}
\end{landscape}

表\ref{tab:acc}は各予測指標の全企業平均を四半期別と全予測期間で集計したものを示している。まず、単変量モデル間での予測精度を比較すると、MAEが最も低いモデルは

次に、多変量モデル間での予測精度を比較すると

さらに、多変量モデルと単変量モデルの予測精度をを比較すると、多変量線形回帰モデルはいずれも単変量線形時系列モデルの精度を下回る結果となった一方、多変量機械学習モデルは単変量機械学習モデルよりも予測精度が向上する傾向があった。この結果から、ファンダメンタル会計変数には将来の四半期EPSを予測する情報があり、その情報は線形的なモデルでは捉えられないことを示唆する。多変量機械学習モデル(特にLASSO回帰モデル, Elastic Net回帰モデル, ランダムフォレスト回帰モデル)は推定したモデルの中でも最も予測精度が高く, 

% NNモデルの精度が低い理由として、データが少ないこと(また、Hill et al.)

また、どのモデルに関しても第4四半期の予測が他の四半期よりも精度が低い結果となっている。先行研究\citep{}でも同様な傾向が確認されており、これに関して\cite{sakurai1990}は...と解釈している。

\section{時系列モデル間の予測精度差の検定}

% フリードマン?
各モデル間の予測精度差の統計的有意性を調べるためのDM検定の結果を表\ref{tab:dm}にまとめている。

\begin{landscape}
\begin{table}
    % \centering
    \caption{DM検定}
    \label{tab:dm}
    % \scalebox{0.6}[0.6]{
    %   \input{./img/}
    % }
\end{table}
\end{landscape}

\section{アナリスト予測との予測精度比較}

本稿では、時系列モデルによる予測と人的な予測の精度を比較するために、人的な予測としてI/B/E/S(Institutional Brokers Estimate System)業績予想を用いる。I/B/E/S業績予想は、複数のアナリストの利益予想の平均値であるコンセンサス予想であり、日本においても四半期EPS予測がカバーされている企業がある\footnote{アナリストは全ての上場企業を調査対象としているわけではない。}。I/B/E/S業績予想は通常、毎月第3金曜日に更新されており、本稿の時系列モデルの予測のタイミングと揃えるためにI/B/E/S業績予想の各四半期の中間月末(5月末, 8月末, 11月末, 2月末)時点の1期先四半期EPSデータを比較対象とする。

\begin{figure}
  \centering
  \caption{I/B/E/S業績予想の更新タイミング}
  \label{fig:ibes_timing}
  \includegraphics[width=12cm]{./img/_ibes_timing.png}
\end{figure}

I/B/E/S業績予想のデータは「I/B/E/S on Datastream」から収集している。I/B/E/S業績予想のサンプルについては、(\ref{sec:sample})節と同様な基準のもとで選択し、予測期間についても時系列モデルと同様に2018年度第1四半期~2020年度第4四半期とする。結果として88社、延べ 88社 × 12四半期 = 1,056個の企業四半期予測が得られた。なお、時系列モデルとI/B/E/S業績予想の予測精度を比較するために、時系列モデル予測については計算可能であった1,003社から、I/B/E/S業績予想が調査対象としている88社に減らして、予測評価対象企業をI/B/E/S業績予想と揃えることとする。表\ref{tab:acc_ibes}は時系列モデルとI/B/E/S業績予想の、各予測指標の全88社平均を四半期別と全予測期間で集計したものを示している。

\begin{landscape}
\begin{table}
    % \centering
    \caption{時系列モデルによる予測とI/B/E/S業績予想の精度比較(88社平均)}
    \label{tab:acc_ibes}
    % \scalebox{0.6}[0.6]{
    %   \input{./img/accuracy_edit.tex}
    % }
\end{table}
\end{landscape}

どっこいどっこい

IBESのほうがいい --> アナリストは時系列モデルで利用しファンダメンタル会計変数以外にも多くの情報を織り込んでいる。--> にもかかわらず

ちなみに、時系列モデルの精度は計算可能な1,003社平均よりもI/B/E/S業績予想が調査対象としている88社平均のほうが全体的に高い傾向がみられる。つまり、I/B/E/S業績予想のアナリストは予測が比較的容易な企業を調査の対象とする傾向がある可能性がある。そもそもアナリストは全ての上場企業をカバーしておらず、\cite{nakai2004}によるとアナリストは情報が入手しやすい企業をカバーする傾向にあるとしている。
% 投資機会の拡張、平等な投資機会という意味でも時系列モデルはいいのでは? 米山(2010)

\section{アナリスト予測との予測精度差の検定}

\part{予測の投資指標としての有用性}

最後に、機械学習アルゴリズムによって得られた1期先四半期EPS予測の投資指標としての有用性について検証する。検証方法としては、代表的な投資指標である株価収益率を1期先四半期EPS予測値をもとに算出し、得られた株価予測収益率の高低によってロング・ショート・ポートフォリオを構築してどれくらいの超過リターンが得られるかを調べる。具体的には次のように行う。

\begin{enumerate}
  \item 時点$t-1$(各四半期の中間月末)において、株価$P_{t-1}$と1期先四半期EPS予測値$\hat{y}_t$を用いて株価予測収益率$\frac{P_{t-1}}{\hat{y}_t}$を全企業に対して計算する。
  \item 各企業の株価予測収益率を降順にソートし、倍率順に1~5までの5つのポートフォリオを作成する。
  \item 高倍率企業で構成されるポートフォリオ1を空売りし、低倍率企業で構成されるポートフォリオ5を同じ額だけ買う。
  \item 1四半期(3ヶ月)保有し、ポートフォリオ1とポートフォリオ5のスプレッドを観測する。
\end{enumerate}

以上のようにロング・ショート・ポートフォリオ戦略を毎四半期行い、ポートフォリオを3ヶ月ごとにリバランスする。図ref{}は

% 図の注)リターン算出に用いた株価データは「日経NEEDS-FinancialQUEST」から収集している。
% 実績値をそのまま予測値とするRWやSRWはPERを用いた戦略とみなせる。

\part{終わりに}

森(1998)の会計の話を少し入れるか

多変量機械学習モデルは,,,,
* 伝統的な単変量線形モデルよりもいい。
* アナリストとはどっこいどっこい。検定すればむしろ勝ち。
* アナリストのカバーは少ないしコスト高い。統計機械モデルはデータがあればどんな企業でもできるし0円
--> アナリストカバレッジの偏りの是正

% https://www.eng.u-hyogo.ac.jp/faculty/hoshino/pc/tex_bibtex/
% http://mikilab.doshisha.ac.jp/dia/seminar/latex/doc/bib.html
\bibliographystyle{agsm} % Harvard style
\bibliographystyle{jplain}
\bibliography{ref}

\end{document}
