{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. イントロ\n",
    "\n",
    "なぜ四半期? --> 投資家にとっての情報開示、企業の透明性。ビジネスダイナミクスの変化の頻度。などなど。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 過去の研究\n",
    "\n",
    "予測対象、期間、結果のまとめたテーブルがあると親切かも。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. データ\n",
    "\n",
    "## サンプルデータ\n",
    "\n",
    "日本の四半期報告制度は比較的新しく、2007年の企業会計基準委員会(ASBJ)による企業会計基準第12号「四半期財務諸表に関する会計基準」及び企業会計基準適用指針第14号「四半期財務諸表に関する会計基準の適用指針」の公表以降、上場企業の四半期報告書の提出が義務付けられた(注)。\n",
    "\n",
    "(注) 2011年に企業会計基準委員会(ASBJ)は改正企業会計基準第12号「四半期財務諸表に関する会計基準」及び改正企業会計基準適用指針第14号「四半期財務諸表に関する会計基準の適用指針」等の公表をしている。この四半期報告制度の改正では財務諸表作成者の作成負担を考慮し、いくつかの四半期情報の開示を義務ではなく任意としている。それに伴い、四半期報告制度の改正以降、資本的支出と期末従業員数の観測される頻度が減り、欠損が多く見られる。Zhang et al. (2004)は四半期単位で欠損している資本的支出と期末従業員数について、資本的支出は毎四半期均等であるとし、期末従業員数は前期の値を維持すると仮定して、欠損値を補填している。本稿でもこの方法に倣って資本的支出と期末従業員数の欠損処理を行うこととする。\n",
    "\n",
    "これにより、四半期データを分析の単位とする本稿では、サンプル期間を四半期報告制度が適用された2008年度(2008年4月1日)から現在2020年度(2021年3月31日)までの計52四半期とする。また、本稿の分析対象企業(サンプル企業)を、サンプル期間において以下の基準で選択する。\n",
    "\n",
    "* 東京証券取引所一部上場企業\n",
    "* 3月決算企業\n",
    "* 一般事業者(「銀行業」、「証券、商品先物取引業」、「保険業」、「その他金融業」を除く)\n",
    "\n",
    "四半期EPS(3ヶ月)およびファンダメンタル会計変数の算出に必要な四半期会計データは「日経NEEDS-FinancialQUEST」から収集している。結果、1089社、延べ 1089社 × 52四半期 = 56,628個の企業-四半期が最終サンプルである。図表_はサンプル企業の所属業種の割合を示している。なお、所属業種は証券コード協議会の中分類(全33種)に基づいている。\n",
    "\n",
    "\n",
    "![ind_cat](/mnt/d/0ngoing/thesis/repo/paper/my_writing/imgs/_ind_cat_table.png) \n",
    "\n",
    "## 目的変数\n",
    "\n",
    "予測の対象となる四半期1株あたり利益(四半期EPS)は以下のように定義される。\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    Y : \\text{四半期 1株あたり利益}\n",
    "    &= \\frac{普通株式に係る四半期当期純利益}{普通株式の期中加重平均株式数} \\\\\n",
    "    \\\\\n",
    "    &= \\frac{損益計算書上の四半期当期純利益-普通株式に帰属しない金額}{普通株式の期中加重平均発行済株式数 - 普通株式の期中加重平均自己株式数} \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "(注) diluted(潜在株式調整後1株当たり当期純利益金額)はどうする? --> そもそも Lai and Li (2007) では両方使ってるけど、変わりないってある。FQはdilutedの欠損が多い。(dilutedしなくていい場合は開示しないから欠損をbasicで代入していいかも?)\n",
    "https://www.shinnihon.or.jp/corporate-accounting/commentary/other/2014-11-17.html\n",
    "\n",
    "## 説明変数\n",
    "\n",
    "単変量モデルによる四半期EPS予測は、過去の四半期EPSのみを説明変数として用いる。一方、多変量モデルによって四半期EPSを予測する場合は、過去の四半期EPSに加えて、Lev and Thiagarajan (1993)やAbarbanell and Bushee (1997)が企業の将来のEPSに対して予測能力を持つと言及しているファンダメンタル会計変数を説明変数として用いる。本稿では、ファンダメンタル会計変数を実際に四半期EPS予測に用いたZhang et. al. (2004)に倣って以下のように7つのファンダメンタル会計変数を定義する。\n",
    "\n",
    "<!-- $$\n",
    "\\begin{align}\n",
    "    INV &: \\text{棚卸資産 (Inventory)} \\\\\n",
    "    AR &: \\text{売掛金 (Accounts receivables)} \\\\\n",
    "    CAPX &: \\text{資本的支出 (Capital expendituture)} \\\\\n",
    "    GM &: \\text{売上総利益 (Gross margin)} \\\\\n",
    "    SA &: \\text{販売費及び一般管理費(Selling and administrative expenses)} \\\\\n",
    "    ETR &: \\text{実効税率 (Effective tax rate)} &=& \\frac{法人税}{税引前利益} \\\\\n",
    "    LF &: \\text{労働力 (Laborforce)} &=& \\frac{売上高}{従業員数} \\\\\n",
    "\\end{align}\n",
    "$$ -->\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    INV &=& \\frac{棚卸資産(円)}{普通株式の期中加重平均株式数} \\\\\n",
    "    \\\\\n",
    "    AR &=& \\frac{売掛金(円)}{普通株式の期中加重平均株式数} \\\\\n",
    "    \\\\\n",
    "    CAPX &=& \\frac{資本的支出(円)}{普通株式の期中加重平均株式数} \\\\\n",
    "    \\\\\n",
    "    GM &=& \\frac{売上総利益(円)}{普通株式の期中加重平均株式数} \\\\\n",
    "    \\\\\n",
    "    SA &=& \\frac{販売費及び一般管理費(円)}{普通株式の期中加重平均株式数} \\\\\n",
    "    \\\\\n",
    "    ETR &=& \\frac{法人税(円)}{税引前利益(円)} \\\\\n",
    "    \\\\\n",
    "    LF &=& \\log{\\left(\\frac{売上高(円)}{従業員数(人)}\\right)} \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "多変量モデルによる予測では四半期EPSとファンダメンタル会計変数の4期までのラグを説明変数として用いる。図表_は予測に用いた変数の記述統計、及び相関行列を示している。\n",
    "\n",
    "![var_sum](/mnt/d/0ngoing/thesis/repo/paper/my_writing/imgs/_variable_sum_table.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 予測モデル\n",
    "\n",
    "## 予測のデザイン\n",
    "\n",
    "本稿では、サンプル企業1089社について、それぞれ1社ごとに1四半期先予測を12期(3年)分行う。まず、ある企業の全52四半期サンプル期間(注)をもとに、1つあたり長さ41期のローリングサンプル(rolling sample)を12個形成する。次に、1つのローリングサンプルを、過去40期の訓練データ(training data, in-sample)と最新1期のテストデータ(test data, out-of-sample)に分ける。そして訓練データを用いてモデルを推定し、テストデータと同じ期にあたる1期先の予測を行う。これを12個のローリングサンプルで繰り返すことによって、ある企業の1四半期先予測が12期分得られる。\n",
    "\n",
    "つまり具体的には、ある企業の全52四半期サンプル期間 $(Data_{\\text{2008Q1}}, Data_{\\text{2008Q2}}, \\cdots, Data_{\\text{2020Q4}})$ から12個のローリングサンプルを作り、1つ目の長さ41期のローリングサンプル $(Data_{\\text{2008Q1}}, Data_{\\text{2008Q2}}, \\cdots, Data_{\\text{2017Q4}}, Data_{\\text{2018Q1}})$ を長さ40期の訓練データ $(Data_{\\text{2008Q1}}, Data_{\\text{2008Q2}}, \\cdots, Data_{\\text{2017Q4}})$ と長さ1期のテストデータ ($Data_{\\text{2018Q1}})$ に分け、訓練データを用いてモデルを推定し、テストデータの説明変数を代入して訓練データの1期先の四半期EPS $y_{2018Q1}$ の予測値 $\\hat{y}_{2018Q1}$ を求める。2つ目のローリングサンプル $(Data_{\\text{2008Q2}}, Data_{\\text{2008Q3}}, \\cdots, Data_{\\text{2018Q1}}, Data_{\\text{2018Q2}})$ も同様に 訓練データ $(Data_{\\text{2008Q2}}, Data_{\\text{2008Q3}}, \\cdots, Data_{\\text{2018Q1}})$ を用いて1期先の四半期EPSの予測値 $\\hat{y}_{2018Q2}$ を求める。同様に他のローリングサンプルに対しても、それぞれ同じモデルを異なる期間の訓練データで推定し、1企業につき12期分の1四半期先予測値系列 $(\\hat{y}_{2018Q1}, \\hat{y}_{2018Q2}, \\cdots, \\hat{y}_{2018Q2})$ が得られる。この予測プロセスを全サンプル企業1089社に対して行うことで、最終的に$12期 \\times 1089社 = 13,068個$の四半期EPS予測値が各予測手法から算出される。\n",
    "\n",
    "(注) 実際には説明変数にラグ変数を含める。したがって利用できるサンプル期間は$52-\\text{ラグの次数}$である。モデルのデザインによってラグの次数は異なるため、利用できる訓練データの長さもモデルによって異なる。\n",
    "\n",
    "図表_は本稿のローリングサンプルによる1期先予測の概要を示している。\n",
    "\n",
    "![rolling_sample](/mnt/d/0ngoing/thesis/repo/paper/my_writing/imgs/_rolling_sample.png) \n",
    "<!-- blender使って、企業の軸も入れて3Dにするとかっこいい? -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 伝統的時系列モデル\n",
    "\n",
    "### ランダムウォークモデル\n",
    "\n",
    "もっとも単純な単変量モデルであるランダムウォークモデルは次のとおりである。\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    & Y_t = Y_{t-1} + \\epsilon_t \\\\\n",
    "    & ただし, \\epsilon_t は全ての時点 t において \\\\\n",
    "    & E[\\epsilon_t] = 0 \\\\\n",
    "    & E[\\epsilon_t \\epsilon_{t-k}] = \\left\\{\n",
    "        \\begin{array}{ll}\n",
    "        \\sigma^2 & k=0 \\\\\n",
    "        0 & k \\neq 0\n",
    "\\end{array}\\right. \\\\\n",
    "\n",
    "    & を満たすホワイトノイズである. \\\\\n",
    "    \\\\\n",
    "    & E[Y_t] = Y_{t-1} \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "一方、四半期EPS時系列には１年単位での季節的変動パターンがあると考えられる。そこでランダムウォーク過程を1四半期単位ではなく、1会計年度単位(4四半期)であると考慮した季節ランダムウォークモデルが次のとおりである。\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    & Y_t = Y_{t-4} + \\epsilon_t \\\\\n",
    "    \\\\\n",
    "    & E[Y_t] = Y_{t-4} \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "ランダムウォークモデルは前四半期の実績値を、季節ランダムウォークモデルは前年同四半期の実績値を予測値とするモデルであり、どちらも実際の予測においてパラメータを推定する工程がない単純なモデルである。そこで、本稿ではランダムウォークモデル及び季節ランダムウォークモデルを他の予測に対するベンチマークとして用いる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARIMAモデル\n",
    "\n",
    "従来の四半期EPSを予測する単変量線形時系列モデルとして、自己回帰和分移動平均(AutoRegressive Integrated Moving Average: ARIMA)モデル(Box and Jenkins, 1977)、特にデータの季節性にも対応できるように一般化した季節自己回帰和分移動平均(Seasonal AutoRegressive Integrated Moving Average: SARIMA)モデルを用いる。$B^nY_t = y_{t-n}$ と定義されるような$B$(backshift operator)を導入すると、SARIMAモデルの一般形は以下のとおりである。\n",
    "\n",
    "注) ARIMAモデルは提唱者の名前からBox-Jenkinsモデルとも呼ばれる。\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\phi_p(B)\\Phi_{P}(B)(1-B)^d(1-B^s)^DY_t &= \\theta_q(B)\\Theta_Q(B^s)a_t \\\\\n",
    "    ただし, \\\\\n",
    "    p &: トレンドの自己回帰過程の階数 \\\\\n",
    "    d &: トレンド階差の次数 \\\\\n",
    "    q &: トレンドの移動平均過程の階数 \\\\\n",
    "    P &: 季節変動の自己回帰過程の階数 \\\\\n",
    "    D &: 季節階差の次数 \\\\\n",
    "    Q &: 季節変動の移動平均過程の階数 \\\\\n",
    "    s &: 季節変動の周期 \\\\\n",
    "    \\phi_p(B) &= (1 - \\phi_1B - \\cdots - \\phi_pB^p) \\\\\n",
    "    \\theta_q(B) &= (1 - \\theta_1B - \\cdots - \\theta_qB^q) \\\\\n",
    "    \\Phi_P(B^s) &= (1 - \\Phi_1B^s - \\cdots - \\Phi_PB^{sP}) \\\\\n",
    "    \\Theta_Q(B^s) &= (1 - \\Theta_1B^s - \\cdots - \\Theta_QB^{sQ}) \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "注) 定数項$\\theta_{\\mu}=(1-\\phi_1-\\cdots-\\phi_p)\\mu$は階差をとれば0となるため、通常の取り扱いに従って0としている。\n",
    "\n",
    "通常、SARIMAモデルは$(p, d, q) \\times (P, D, Q)$の値の組み合わせをBox-Jenkins法によってデータごとに選定し、モデルの構築を行う。一方、これまでの四半期EPSの時系列予測の分野では全ての企業に適合するSARIMAモデルが探求され、次の3つのSARIMAモデル(Foster, 1977; Griffin, 1977; Watts, 1975; Brown and Rozeff, 1979)があらゆる企業の四半期EPSの時系列特性を描写するモデルであるとされている。(注)\n",
    "\n",
    "(注)先行研究では、企業ごとにモデルを構築するよりも、企業で共通の構築で予測したほうが全体として予測のパフォーマンスが良いと示されている。\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\text{ Foster (1977) } &: (p, d, q) \\times (P, D, Q)_s = (1, 0, 0) \\times (0, 1, 0)_4 \\\\\n",
    "    Y_t &= Y_{t-4} + \\phi_1(Y_{t-1} - Y_{t-5}) + a_t \\\\\n",
    "    E[Y_t] &= Y_{t-4} + \\phi_1(Y_{t-1} - Y_{t-5}) + \\delta \\\\\n",
    "    \\\\\n",
    "    \\text{ Griffin (1977), Watts (1975) } &: (p, d, q) \\times (P, D, Q)_s = (0, 1, 1) \\times (0, 1, 1)_4 \\\\\n",
    "    Y_t &= Y_{t-4} + (Y_{t-1} - Y_{t-5}) - \\theta_1a_{t-1} - \\Theta_1a_{t-4} + \\theta_1\\Theta_1a_{t-5} + a_t \\\\\n",
    "    E[Y_t] &= Y_{t-4} + (Y_{t-1} - Y_{t-5}) - \\theta_1a_{t-1} - \\Theta_1a_{t-4} + \\theta_1\\Theta_1a_{t-5} + \\delta \\\\\n",
    "    \\\\\n",
    "    \\text{ Brown and Rozeff (1979) } &: (p, d, q) \\times (P, D, Q)_s = (1, 0, 0) \\times (0, 1, 1)_4 \\\\\n",
    "    Y_t &= Y_{t-4} + \\phi_1(Y_{t-1}-Y_{t-5}) - \\Theta_1a_{t-4} + a_t \\\\\n",
    "    E[Y_t] &= Y_{t-4} + \\phi_1(Y_{t-1}-Y_{t-5}) - \\Theta_1a_{t-4} + \\delta \\\\\n",
    "    \\\\\n",
    "    & \\text{ただし, }\\delta\\text{はSARIMAモデルの定数項.}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "本稿では先行研究に倣い、特に支持されてきたこの3つのモデルを単変量線形時系列モデルとして用いることとする。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多変量線形モデル\n",
    "\n",
    "ファンダメンタル会計変数が将来の四半期EPSを線形に説明するかどうかについて確かめるため、Lev and Thaigarajan (1993)、Abarbanell and Bushee (1997)、Lorek and Willinger (1996)の研究で用いられているモデルを基に、以下のような多変量線形回帰モデルを考える。\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    E[Y_t] &= \\alpha + \\beta_1Y_{t-1} + \\beta_2Y_{t-4} + \\beta_3INV_{t-1} + \\beta_4AR_{t-1} + \\beta_5CAPX_{t-1} + \\beta_6GM_{t-1} + \\beta_7SA_{t-1} + \\beta_8ETR_{t-1} + \\beta_9LF_{t-1} \\\\\n",
    "    E[Y_t] &= \\alpha + \\beta_1Y_{t-1} + \\beta_2Y_{t-4} + \\beta_3INV_{t-4} + \\beta_4AR_{t-4} + \\beta_5CAPX_{t-4} + \\beta_6GM_{t-4} + \\beta_7SA_{t-4} + \\beta_8ETR_{t-4} + \\beta_9LF_{t-4} \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "2つのモデルはどちらも、四半期EPSの1四半期前ラグ$Y_{t-1}$と4四半期前ラグ$Y_{t-4}$が自己回帰的な説明変数として含まれている。両者の違いとしてはファンダメンタル会計変数のラグの次数にあり、1つ目(式(#))のモデルではファンダメンタル会計変数の1四半期前ラグを、2つ目のモデルでは季節性を考慮してファンダメンタル会計変数の4四半期前ラグをモデルの説明変数として含めている。一方、Cao and Parry (2009) は後述する機械学習モデルと利用できる情報の公平性に保つため、以下のように四半期EPSとファンダメンタル会計変数のラグ変数を1四半期前、2四半期前、3四半期前、4四半期前すべて含めた多変量線形回帰モデルを推定している。\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    E[Y_t] &= \\alpha + \\sum^{4}_{\\tau=1} \\left( \\beta_{1\\tau}Y_{t-\\tau} + \\beta_{2\\tau}INV_{t-\\tau} + \\beta_{3\\tau}AR_{t-\\tau} + \\beta_{4\\tau}CAPX_{t-\\tau} + \\beta_{5\\tau}GM_{t-\\tau} + \\beta_{6\\tau}SA_{t-\\tau} + \\beta_{7\\tau}ETR_{t-\\tau} + \\beta_{8\\tau}LF_{t-\\tau} \\right) \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "<!-- 以上のファンダメンタル会計変数を説明変数として用いた多変量線形回帰モデルを多変量モデルのベンチマークとして、他の手法による多変量予測と比較する。 -->\n",
    "なお、これらのモデルのパラメータは最小二乗法を用いてを推定する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 機械学習モデル\n",
    "\n",
    "金融データは高次元、7変数しかもラグ、普通のモデルは変数多いと精度下がる。機械学習で次元削減。\n",
    "金融データは非線形。非線形なモデル2つ。AnnとノンパラなRF\n",
    "\n",
    "ここでは、本稿で用いる機械学習的手法について紹介する。\n",
    "\n",
    "なお、以下より共通して説明変数ベクトル${\\bf X}$については、単変量モデルにおいて、\n",
    "\n",
    "$$\n",
    "{\\bf X} = (Y_{t-1}, Y_{t-2}, Y_{t-3}, Y_{t-4})\n",
    "$$\n",
    "\n",
    "多変量モデルにおいて、\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "{\\bf X} = (\n",
    "    & Y_{t-1}, Y_{t-2}, Y_{t-3}, Y_{t-4}, \\\\\n",
    "    & INV_{t-1}, INV_{t-2}, INV_{t-3}, INV_{t-4}, \\\\\n",
    "    & AR_{t-1}, AR_{t-2}, AR_{t-3}, AR_{t-4}, \\\\\n",
    "    & CAPX_{t-1}, CAPX_{t-2}, CAPX_{t-3}, CAPX_{t-4}, \\\\\n",
    "    & GM_{t-1}, GM_{t-2}, GM_{t-3}, GM_{t-4}, \\\\\n",
    "    & SA_{t-1}, SA_{t-2}, SA_{t-3}, SA_{t-4}, \\\\\n",
    "    & ETR_{t-1}, ETR_{t-2}, ETR_{t-3}, ETR_{t-4}, \\\\ \n",
    "    & LF_{t-1}, LF_{t-2}, LF_{t-3}, LF_{t-4}\n",
    "    )\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "としてモデルを構築する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 人工ニューラルネットワークモデル\n",
    "\n",
    "人工ニューラルネットワーク(Artificial Neural Network: ANN)モデルについて述べる。まずANNの構造の最小単位であるユニット(unit)またはニューロン(neuron)について考える。$(X_1, \\cdots, X_k)$を入力ベクトルとする。$(w_1, \\cdots, w_k)$は入力ベクトルの要素それぞれに対応する重み(weight)であり、スカラー値$b$はバイアス(bias)という。ユニットではまず始めに$(X_1, \\cdots, X_k)$と$(w_1, \\cdots, w_k)$の内積と$b$の和であるプレアクティベーション(pre-activation)$z$を計算する。\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    z = w_1 X_1 + \\cdots + w_k X_k + b\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "次に$z$は非線形な関数である活性化関数(activation function) $\\phi(\\cdot)$ に渡され、アクティベーション(activation)$a$として出力される。\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    a = \\phi(z)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "以上がANNのユニットの構造であり、まとめると以下の式で表される。\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    a = \\phi(w_1 X_1 + \\cdots + w_k X_k + b)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "![ann_unit](/mnt/d/0ngoing/thesis/repo/paper/my_writing/imgs/_ann_unit.png)\n",
    "\n",
    "このユニットを複数組み合わせることで、ANNが構成される。\n",
    "\n",
    "ANNと一口に言っても様々な構造をもつ多くの種類がある。ANNの1種である順伝播型ニューラルネットワーク(feed-forward neural network: FFNN)はANNのなかでも基本的な構造を持ち、全てのユニットが結合した無閉路グラフ(acyclic graph)で表現されすべての計算が逐次的に行われる。FFNNの最も代表的なネットワークは多層パーセプトロン(multilayer perceptron: MLP)であり、図表_のように表される。\n",
    "\n",
    "![ann_mlp](/mnt/d/0ngoing/thesis/repo/paper/my_writing/imgs/_ann_mlp.png)\n",
    "\n",
    "MLPの特徴として、横のつながりのユニットをそれぞれ層としてまとめると少なくとも3つ以上の層から構成される。またMLPはネットワークの全てのユニットが次の層に含まれる全てのユニットとそれぞれ結合している(fully connected)。ネットワークの最初の層は入力層(input layer)といい入力される特徴量がここにあたる。最後の層は出力層(output layer)といいネットワークが出力する値であり、出力層のアクティベーションは予測値を表す。この2つを除いた間の層は全て隠れ層(hidden layer)といい、MLPの多層構造を作る。\n",
    "\n",
    "例えば、入力層と1層の隠れ層、出力層から成る3層パーセプトロンを定式化してみる。まず、隠れ層のアクティベーションをベクトル$(H_1, \\cdots, H_L)$とする(activation vector)。ただし、$L$は隠れ層に含まれるユニットの数である。また、隠れ層の活性関数を $\\phi^{(1)}(\\cdot)$ とし、隠れ層のバイアス項を$(b^{(1)}_1, \\cdots, b^{(1)}_L)$とすると、隠れ層のアクティベーションは以下のように表される。\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    H_1 &= \\phi^{(1)}(w^{(1)}_{11} X_1 + w^{(1)}_{21} X_2 + \\cdots + w^{(1)}_{K1} X_K + b^{(1)}_1) \\\\\n",
    "    H_2 &= \\phi^{(1)}(w^{(1)}_{12} X_1 + w^{(1)}_{22} X_2 + \\cdots + w^{(1)}_{K2} X_K + b^{(1)}_2) \\\\\n",
    "    \\vdots \\\\\n",
    "    H_L &= \\phi^{(1)}(w^{(1)}_{1L} X_1 + w^{(1)}_{2L} X_2 + \\cdots + w^{(1)}_{KL} X_K + b^{(1)}_L) \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "次に、出力層のについて考える。予測する変数は本稿では1次元であるため、出力層のアクティベーションはスカラー$Y$となる。出力層の活性関数を$\\phi^{(2)}(\\cdot)$とし、バイアス項を$b^{(2)}$とすると、出力層のアクティベーション(または予測値)は以下のように表される。\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    Y = \\phi^{(2)}(w^{(2)}_{1} H_1 + w^{(2)}_{2} H_2 + \\cdots + w^{(2)}_{L} H_L + b^{(2)})\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "このように、MLPは線形結合モデルを非線形変換したものの繰り返しであることがわかる。このMLPの隠れ層の数を増やすことで、ネットワークをより深くすることができ、深層ニューラルネットワークが構築できる。一方、Qi (1999)は隠れ層のユニット数が十分であれば、隠れ層が1つで、隠れ層の活性化関数にロジスティック関数、出力層の活性化関数に恒等関数を用いた3層パーセプトロンは、あらゆる連続関数を近似できると述べている。そこで本稿は、Callen et al. (1997) や Zhang et al. (2004)と同様に以下のような3層パーセプトロンANNモデルを用いる。\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    Y_t &= f({\\bf X, \\alpha, \\beta}) =\\sum^{L}_{l=1} \\left( \\alpha_l H_l + \\alpha_0 \\right)= \\sum^{L}_{l=1} \\alpha_l \\text{logsig} \\left(\\sum^{K}_{k=1} \\left( \\beta_{kl} X_k + \\beta_{0l} \\right) \\right) \\\\\n",
    "    ただし、\\\\\n",
    "    Y_t &: 出力(目的変数) \\\\\n",
    "    {\\bf X}=(X_1, \\cdots, X_{K}) &: 入力(説明変数)ベクトル \\\\\n",
    "    X_k &: k番目の入力(説明変数) \\\\\n",
    "    \\alpha_l &: 隠れ層のl番目のユニットと目的変数のウェイト(パラメータ) \\\\\n",
    "    L &: 隠れ層のユニット数 \\\\\n",
    "    \\alpha_0 &: 出力層のバイアス(定数項) \\\\\n",
    "    \\beta_{kl} &: k番目の入力(説明変数)と隠れ層のl番目のユニットのウェイト(パラメータ) \\\\\n",
    "    \\beta_{0l} &: 隠れ層のl番目のユニットのバイアス(定数項) \\\\\n",
    "    \\text{logsig}(\\cdot) = \\frac{\\exp(\\cdot)}{1 + \\exp(\\cdot)} &: ロジスティック関数\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "なお、ANNモデルの推定は誤差逆伝播法(Backward propagation algorithm)を用いてウェイトの勾配を計算し、勾配降下によって行う。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 正則化回帰モデル\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    a\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "### ランダム・フォレスト回帰モデル\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    a\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ハイパーパラメータの選択\n",
    "\n",
    "![rolling_sample_val_it](/mnt/d/0ngoing/thesis/repo/paper/my_writing/imgs/_rolling_sample_val_it.png)\n",
    "\n",
    "![rolling_sample_val_i](/mnt/d/0ngoing/thesis/repo/paper/my_writing/imgs/_rolling_sample_val_i.png)\n",
    "\n",
    "## 予測精度指標\n",
    "図表_は、これまでに述べた本稿で用いる各時系列予測モデルをまとめている(単変量か、伝統的かでカテゴリ分類)。各時系列予測モデルの予測精度を比較するために、\n",
    "\n",
    "<モデル一覧table, 変数表記> <-- Random Forestはどう表記する?\n",
    "\n",
    "各モデルの四半期EPS予測の精度を測るために、以下の精度指標を用いる。\n",
    "\n",
    "平均絶対誤差率(Mean Absolute Percentage Error: MAPE)\n",
    "\n",
    "$$\n",
    "\\text{MAPE} = \\frac {1} {N} \\sum^{N}_{i=1}\\left| \\frac {(Y_t - \\hat{Y}_t)} {Y_t} \\right|\n",
    "$$\n",
    "\n",
    "平均二乗誤差率(Mean Squared Percentage Error: MSPE)\n",
    "\n",
    "$$\n",
    "\\text{MSPE} = \\frac {1} {N} \\sum^{N}_{i=1} \\left( \\frac { ( Y_t - \\hat{Y}_t)} {Y_t} \\right) ^2\n",
    "$$\n",
    "\n",
    "ただし、$N$はテストデータのサンプルサイズであり、本稿では12期間である。なお、絶対予測誤差率$ |\\frac{Y_t -{\\hat Y}_t}{Y_t}|$が1を超える予測サンプル(予測結果)について、Brown and Rozeff (1979) Zhang et al. (2004)、Lorek and Willinger (1996)に倣い絶対予測誤差率の上界(Upper Bound)を1とし、この制約に基づいて算出した精度指標を報告することとする。また、そのような予測サンプルはLarge forecast errorサンプルとし、予測精度指標と併せてLarge forecast errorの割合も報告する。\n",
    "\n",
    "フリードマン検定の説明\n",
    "\n",
    "Wilcoxon signed-rank test\n",
    "\n",
    "binomial test\n",
    "\n",
    "DM-testの説明\n",
    "\n",
    "仮説1: 企業$i$について、ランダムウオークと機械学習モデルの精度に差はない。\n",
    "\n",
    "仮説2: 企業$i$について、ARIMAモデルと機械学習モデルの精度に差はない。\n",
    "\n",
    "仮説3: 企業$i$について、IBESと機械学習モデルの精度に差はない。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 予測の精度と結果 --> 予測手法のすぐ下でもいいかも?\n",
    "\n",
    "\n",
    "## 予測結果と予測精度の優位性比較 (Diebold-Mariano検定)\n",
    "\n",
    "1089社 ARIMAとの比較\n",
    "\n",
    "![result_accuracy](/mnt/d/0ngoing/thesis/repo/paper/my_writing/imgs/_result_accuracy.png)\n",
    "\n",
    "<DM検定カウントテーブル>\n",
    "\n",
    "<DMテスト結果(hist)>\n",
    "\n",
    "## IBES比較\n",
    "\n",
    "Zhang et. al. (2004) が future research において ANN予測とアナリスト予測の比較をするべきだと言及している。\n",
    "\n",
    "99社 IBESとの比較\n",
    "I/B/E/Sデータの説明はここでもいいかも?\n",
    "\n",
    "I/B/E/S予想データについても、同様な基準でサンプルを選択し、「I/B/E/S on Datastream」から収集している。得られた企業数は99社であり、延べ99 社 × 12 四半期 = ○○個の企業-四半期がサンプルである。\n",
    "\n",
    "<I/B/E/Sテーブル, 業種、アナリスト数>\n",
    "\n",
    "<IBES予測精度指標テーブル>\n",
    "\n",
    "<IBESDM検定カウントテーブル>\n",
    "\n",
    "<DMテスト結果(hist)>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 予測の価値関連性\n",
    "VPRの紹介?、結果\n",
    "\n",
    "<!-- Cao and You (2020) 1. introduction-->\n",
    "企業の将来収益を予測することは、証券価値を決定する上で非常に重要である(Ohlson, 1995; )。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. 終わりに\n",
    "本稿の貢献\n",
    "\n",
    "* 日本企業の収益予測の研究において四半期データを用いたこと。\n",
    "* 日本企業のデータで機械学習モデルを用いて予測し、伝統的時系列モデルとの精度比較を行ったこと。\n",
    "* 日本企業のデータで機械学習モデルを用いて予測し、アナリスト予測との精度比較を行ったこと。\n",
    "* アナリスト予測と統計的モデルと機械学習モデルの組み合わせ予測を行ったこと\n",
    "* 機械学習モデルによる予測で得たEPSを用いてVPRポートフォリオを構築し、予測の価値関連性を確認したこと。\n",
    "* アナリスト予測と統計的モデルと機械学習モデルのそれぞれの予測に基づいたVPRポートフォリオ戦略の収益性の比較。\n",
    "\n",
    "モデルの進化により、企業利益予測において、今まで認識されていた人的な手法と統計的・機械的手法の予測パフォーマンスの優劣が変化していることを示唆する。投資家や経営者は参照する企業利益の予測の手法や主体を見直すべきかもしれない。\n",
    "\n",
    "* 論文数の増加の必要性, 太田 (2008). 日本の予想情報研究をさらに増やそう。的な\n",
    "\n",
    "更に、本稿は統計的・機械的手法の有用性だけでなく、日本における四半期会計情報の有用性も示す。(簡素化がされてるhttps://www.shinnihon.or.jp/corporate-accounting/commentary/quarter/2011-07-14.html、四半期会計廃止の声もあるhttps://www.asahi.com/articles/ASPB85CMTPB8ULFA00B.html)\n",
    "\n",
    "本稿の限界\n",
    "* NNのパフォーマンスの悪さはのチューニング不足の可能性\n",
    "* ポートフォリオは、1期先のみでの価値予測。2, 3, 4期先予測への応用が期待される。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\\\begin{tabular}{lrrrrrrrr}\\n\\\\toprule\\n{} &      Max\\\\_error &  Max\\\\_percentage\\\\_error &         MAE &       MAPE &          MSPE &   MAPE-UB &   MSPE-UB &  Large\\\\_error\\\\_rate \\\\\\\\\\n\\\\midrule\\ny\\\\_test                     &       0.000000 &              0.000000 &    0.000000 &   0.000000 &  0.000000e+00 &  0.000000 &  0.000000 &               NaN \\\\\\\\\\ny\\\\_hat\\\\_rw                   &    1989.290000 &           5895.000000 &   38.745586 &   4.313953 &  7.001957e+03 &  0.584368 &  0.472665 &         12.579523 \\\\\\\\\\ny\\\\_hat\\\\_sarima\\\\_br            &   17667.440089 &          88978.127205 &   38.468179 &   9.708306 &  6.068736e+05 &  0.526985 &  0.410689 &         35.586770 \\\\\\\\\\ny\\\\_hat\\\\_sarima\\\\_f             &    3611.477871 &           2068.166620 &   34.881795 &   2.823022 &  1.142824e+03 &  0.526749 &  0.412805 &          9.417307 \\\\\\\\\\ny\\\\_hat\\\\_sarima\\\\_g             &    3370.115229 &          34626.006762 &   39.409411 &   6.123333 &  9.347221e+04 &  0.534064 &  0.423390 &         20.513912 \\\\\\\\\\ny\\\\_hat\\\\_srw                  &    2685.300000 &           1946.000000 &   33.354025 &   2.703544 &  9.373206e+02 &  0.528642 &  0.415504 &          9.108878 \\\\\\\\\\ny\\\\_hat\\\\_umlp                 &    8148.714600 &         134665.300000 &   53.452910 &  14.806769 &  1.391902e+06 &  0.603029 &  0.489031 &         46.030197 \\\\\\\\\\ny\\\\_hat\\\\_men\\\\_i\\\\_tuned\\\\_simple   &    6511.645744 &           4491.734579 &   28.917411 &   1.883392 &  1.847730e+03 &  0.463227 &  0.346951 &          7.736377 \\\\\\\\\\ny\\\\_hat\\\\_ml1\\\\_i\\\\_tuned\\\\_fine     &    1950.316373 &           3975.668591 &   26.504780 &   1.571230 &  1.361782e+03 &  0.466968 &  0.347463 &          6.804704 \\\\\\\\\\ny\\\\_hat\\\\_ml1\\\\_i\\\\_tuned\\\\_simple   &    6549.907406 &           5870.756027 &   29.542920 &   2.169558 &  2.980864e+03 &  0.471464 &  0.356111 &          8.710456 \\\\\\\\\\ny\\\\_hat\\\\_ml2\\\\_i\\\\_tuned\\\\_simple   &    7930.703279 &          14011.154377 &   43.437875 &   4.271451 &  1.800339e+04 &  0.514150 &  0.407035 &         14.191942 \\\\\\\\\\ny\\\\_hat\\\\_mlgb                 &    6261.705476 &         153237.199088 &   69.511711 &  17.683058 &  1.800189e+06 &  0.627993 &  0.501072 &         61.009583 \\\\\\\\\\ny\\\\_hat\\\\_mlm1                 &   33025.109771 &          19193.225310 &   60.126125 &   5.778863 &  2.955581e+04 &  0.585543 &  0.480527 &         16.114990 \\\\\\\\\\ny\\\\_hat\\\\_mlm2                 &   40758.244860 &         120789.437098 &   71.752135 &  14.285043 &  1.118622e+06 &  0.597033 &  0.494134 &         39.123383 \\\\\\\\\\ny\\\\_hat\\\\_mlm3                 &   37297.954067 &         125258.155053 &   82.168744 &  15.209637 &  1.203296e+06 &  0.609444 &  0.508960 &         40.073381 \\\\\\\\\\ny\\\\_hat\\\\_mlm4                 &  202488.020544 &          50075.354129 &  343.687207 &  31.944189 &  5.131299e+05 &  0.805381 &  0.747106 &         49.054079 \\\\\\\\\\ny\\\\_hat\\\\_mmlp                 &   11637.991000 &           3937.530700 &   39.402030 &   3.837378 &  3.237605e+03 &  0.566839 &  0.452701 &         11.806426 \\\\\\\\\\ny\\\\_hat\\\\_mraf\\\\_i\\\\_tuned\\\\_simple\\\\_ &    2484.391430 &          26081.830720 &   27.490445 &   4.067308 &  5.253424e+04 &  0.467038 &  0.350889 &         16.970240 \\\\\\\\\\ny\\\\_hat\\\\_msvm                 &    2147.120450 &           9720.600176 &   37.145402 &   2.883910 &  7.689420e+03 &  0.599225 &  0.468363 &         10.587755 \\\\\\\\\\n\\\\bottomrule\\n\\\\end{tabular}\\n\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
